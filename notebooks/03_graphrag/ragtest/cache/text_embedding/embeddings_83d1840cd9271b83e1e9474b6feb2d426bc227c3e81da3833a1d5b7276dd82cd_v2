{"result": {"data": [{"embedding": [0.012039229, 0.023835355, -0.15383099, -0.043668684, 0.07248863, 0.006873005, 0.051599845, 0.032282434, -0.027903838, 0.031535808, -0.0057525015, 0.03883382, 0.1002448, 0.04894057, -0.018352171, -0.010301941, -0.0015351692, -0.09150432, -0.0103190085, -0.011434248, -0.04148385, 0.0052611753, 0.032211296, -0.03991698, 0.017661966, 0.0034623188, -0.04121281, -0.0258918, 0.0068493886, 0.040948365, 0.04876624, -0.032030717, -0.00048468658, -0.10057566, -0.041309934, 0.022474397, 0.05750344, -0.02863657, 0.053623084, 0.030810434, 0.06346339, -0.007090415, 0.018706042, 0.0037539743, 0.04247934, 0.0053082625, 0.010654078, -0.02429621, 0.011047908, -0.027139444, 0.044391435, 0.015561572, 0.004318967, 0.016415894, 0.07301104, 0.04473717, -0.06266099, 0.0650141, 0.012299567, -0.07358786, 0.11742516, -0.02033501, -0.08386196, 0.011630418, -0.020019272, -0.0009417773, -0.059570733, -0.008558569, 0.00036787137, 0.00060652976, 0.0029734322, 0.006666668, 0.009753737, 0.020663062, -0.045287605, 0.041002672, 0.0043954165, 0.023848025, -0.009180361, 0.025157826, -0.011466411, 0.032439318, 0.022473628, -0.040569533, 0.027339816, 0.019827046, -0.06837795, 0.033472314, -0.08408757, 0.117281534, 0.0074165156, 0.013660892, 0.04738421, 0.026479764, -0.04947696, 0.0125461025, -0.054710906, -0.0016608548, -0.026511181, -0.025826478, -0.017658137, -0.00389223, -0.0035415208, -0.009503912, -0.002421962, 0.038359333, -0.0113816755, 0.010453975, -0.012631241, -0.03206671, -0.034655195, 0.036662444, -0.033499327, 0.012566152, -0.038457923, -0.05675925, 0.09168869, -0.010325162, -0.02341991, 0.023286972, 0.0028834068, -0.028336601, -0.0007698109, -0.04719502, 0.00085201673, 0.054442164, -0.028869975, 0.0032292767, 0.013456061, 0.0011034778, 0.0008905591, -0.025301745, -0.05157618, -0.0138905905, -0.00037093062, 0.1161942, -0.020159436, -0.010046006, 0.03362281, 0.011056943, -0.022425745, 0.0033053446, -0.011007811, 0.0067870095, 0.022873817, -0.02269771, -0.004754415, -0.034004338, -0.026385266, 0.019316413, 0.029353047, 0.037022352, -0.015220769, 0.008511505, 0.027664157, -0.036315694, 8.402909e-05, -0.0076098805, 0.044537637, 0.0020876238, 0.06541389, -0.037899, 0.033890832, 0.022659035, -0.025379192, 0.01436528, 0.04785977, 0.018413637, 0.050434403, 0.04512909, -0.043356434, -0.052620314, 0.0198616, -0.02676318, 0.032281794, 0.0020606776, 0.047676913, -0.062602505, 0.020577436, -0.014156085, 0.077317394, -0.016594667, 0.05283268, 0.00030075063, 0.0117096305, -0.0020239828, 0.015718492, -0.006039835, -0.0024209546, -0.09163868, 0.03572133, -0.00032641608, -0.06263746, -0.0728799, -0.03749027, -0.04627233, 0.067826055, -0.053862844, 0.012734771, -0.033775307, -0.0059153354, -0.03707125, -0.07220408, 0.057176396, -0.05290722, 0.0415683, 0.024406262, 0.024695462, -0.047675844, 0.028735317, 0.022316735, -0.005715172, 0.03591613, 0.0075764298, 0.009521131, -0.011778844, 0.0027579407, 0.02796687, -0.0039923387, 0.018355485, 0.042891942, 0.0011294443, -7.4940035e-05, 0.0032096994, 0.04471216, 0.00715024, -0.049678627, -0.009160754, -0.032716516, 0.041537564, -0.022413775, -0.04285944, 0.033392973, -0.01541396, -0.024396723, -0.00301877, 0.015436995, -2.4889596e-06, -0.0032535894, 0.006482702, 0.016604379, 0.0579769, -0.0107774, 0.0014450183, -0.06755911, -0.023558343, -0.018427415, -0.0004666991, 0.011259529, 0.0016452259, 0.0019295377, 0.03199394, 0.03428063, -0.029080044, 0.022726728, -0.010167706, -0.03609723, 0.0052725766, 0.034654602, 0.041393664, 0.05013912, 0.027265837, 0.02048571, 0.0061466508, -0.04731429, -0.057634022, 0.01893952, -0.044554025, 0.0030408246, -0.027332306, 0.02755801, 0.011445641, 0.08428716, 0.045407366, 0.03531342, 0.050454672, -0.02746741, -0.01590653, 0.00016034466, 0.013038968, 0.002972761, -0.11201687, -0.013108576, -0.00023259273, 0.024505734, 0.015107299, 0.029554436, -0.016370988, 0.026510162, -0.013212042, 0.015701793, 0.040365327, -0.025762448, -0.026501443, -0.049630947, 0.021209069, 0.0355878, 0.00065454806, 0.040397108, -0.023619857, 0.018402155, 0.034360275, 0.066300064, 0.040767927, 0.02376716, -0.0088342875, -0.025066428, 0.011646661, 0.024115343, 0.023399731, -0.02502224, -0.0037580112, -0.055803373, 0.020635052, -0.030577676, -0.02715128, 0.001464704, 0.009431519, 0.06863374, -0.04511287, 0.021636501, -0.050171204, -0.021309257, 0.001602859, 0.010351, -0.0091957, 0.0092462115, -0.031183662, -0.030176185, -0.0063244747, 0.06290345, 0.042896155, 0.042881045, -0.021022014, -0.038530283, -0.032740343, 0.0015468742, -0.031115185, 0.020907886, -0.00736712, 0.009613033, -0.024268508, 0.00076962926, -0.016570605, -0.025870528, 0.00034581238, -0.032496586, -0.07083255, -0.0032589848, -0.01545813, 0.015723255, -0.017461425, 0.007609804, -0.031683654, 0.04084422, -0.016014783, 0.031035334, 0.031284485, 0.021865241, -0.015218351, 0.027832637, 0.019302381, -0.020033246, -0.041801944, 0.0240777, -0.020577302, 0.039724614, 0.037134707, 0.028504273, -0.0009493271, 0.0076260194, 0.0032089788, -0.035273205, 0.04971069, -0.024161099, 0.04689991, -0.034631494, 0.02429282, 0.0046542645, -0.01382802, -0.021182526, -0.009210648, -0.013043193, -0.052836232, -0.034637265, 0.02942006, -0.0041174437, -0.026901418, -0.0023429226, 0.030055648, 0.0072228704, -0.012862154, -0.062177073, 0.031643435, 0.0115372185, -0.026714887, 0.09148076, 0.028876381, 0.034903154, 0.04053253, -0.03184577, -0.00662796, -0.0017561448, -0.0020838708, -0.03829275, 0.00791535, -0.050150268, 0.011836837, 0.02218465, 0.034646556, -0.008412985, 0.022662224, -0.006594416, -0.052479967, -0.007235185, -0.037637535, 0.024450198, -0.010729017, -0.05524279, -0.01770977, 0.02586951, 0.049462397, -0.013013145, -0.010558389, -0.007187338, 0.016189944, 0.06588694, 0.041923933, -0.00225216, -0.09787222, 0.050566215, 0.013104588, 0.006203648, 0.01363321, 0.037177674, 0.032041844, 0.013507714, -0.009892467, -0.01681015, 0.03572982, 0.039080005, -0.07273121, 0.0010147534, -0.019855952, 0.0032453379, 0.040974785, 0.07050246, -0.011012107, -0.050663657, 0.020249683, -0.008208944, 0.033242654, 0.060212888, 0.018508067, 0.09660576, -0.017259516, 0.027264448, 0.08119712, -0.0002936803, 0.039148476, 0.06636004, 0.02233345, -0.033643834, -0.005429491, -0.012802334, -0.053334866, -0.0056155594, 0.012915, 0.060634203, 0.050479293, -0.056474183, 0.011915453, 0.027411545, 0.0006441564, -0.02043894, 0.00089430466, -0.037401028, 0.006532104, 0.04435406, -0.000660669, 0.014849744, -0.034922976, -0.032336477, -0.068079844, -0.0030042063, 0.030226037, 0.035381887, -0.03424965, 0.03832824, -0.010511206, 0.02733717, 0.04112226, 0.042710897, 0.008720809, -0.041435283, -0.01374268, 0.012938015, 0.04865528, 0.0059878067, -0.03455261, -0.018859372, 0.031875934, -0.0034810759, -0.06953541, -0.013495562, -0.018652478, 0.03370436, -0.048832253, -0.04410047, 0.04400523, -0.011464808, 0.04180422, 0.0184886, 0.050820924, 0.033004973, -0.10761853, 0.04378695, 0.028229848, -0.009541107, 0.007624153, 0.03669153, -0.025434086, -0.0013535402, -0.019341499, -0.032306977, -0.010874223, 0.012323723, -0.06339909, 0.025938142, -0.014465877, 0.037632525, 0.026466023, -0.08141245, -0.0066608535, -0.016978784, -0.022432258, -0.015437439, 0.029104562, -0.02753606, 0.006616003, 0.00790528, 0.013876591, 0.040057868, 0.005856443, -0.00754539, -0.03450462, 0.016078485, 0.0069468175, 0.014014388, -0.109014265, -0.004830105, -0.05489196, 0.046391964, -0.054700915, 0.012732318, -0.029304752, -0.04408586, -0.055679213, -0.009912583, 0.042238563, -0.004750708, -0.01482972, 0.09086456, -0.027232023, 0.012356311, 0.002110492, -0.051084466, -0.007109634, -0.010982767, 0.07079844, 0.050347935, -0.073777735, -0.013637453, 0.049093246, -0.025582446, -0.01182761, 0.015452862, -0.01619225, -0.031936303, -0.074228704, 0.009052555, -0.021413818, 0.0022264833, -0.015173839, -0.028762037, 0.026099, -0.070171505, -0.048884813, 0.019569583, 0.0025765297, 0.019611131, -0.033495724, 0.015151286, -0.02437914, -0.0014254488, -0.04044912, -0.005178648, -0.041065607, -0.017031051, -0.08570659, -0.033736054, 0.020397425, 0.016101861, -0.083078265, 0.023397151, 0.04788613, -0.018551601, 0.047821015, 0.053012904, 0.017391948, -0.012328975, -0.021386316, 0.0059333006, 0.024565538, 0.0065500853, -0.038613025, 0.03265587, -0.020284541, -0.033425253, -0.032033026, -0.06927073, -0.024063827, 0.043405842, -0.032843832, 0.003107332, -0.030322922, 0.013651311, -0.015605575, 0.048388198, 0.034162734, -0.056792434, 0.022923833, -0.03310193, -0.0048913104, -0.070142426, 0.03085664, -0.030945782, 0.00031875362, -0.0018235578, 0.027893415, 0.049868036, -0.032208208, -0.018604772, 0.008587645, 0.019162856, -0.005149537, 0.04009977, 0.079372205, 0.02221912, -0.0035924804, 0.06071152, 0.058885287, -0.0075760074, -0.078493536, -0.02560127, 0.0441057, 0.009061357, 0.028649332, 0.0078596575, -0.008261907, 0.011217034, -0.042822283, 0.015750367, -0.008862299, 0.054103527, -0.026876075, -0.06566771, -0.018479066, -0.0016022169, -0.02614494, 0.021518996, -0.031697765, 0.0060460945, 0.006510863, 0.045854975, 0.00533746, -0.007613831, 0.043306522, 0.015505561, 0.0295382, -0.005580252, -0.032673817, 0.0053818435, -0.01644453, -0.030212479, -0.011577152, 0.011401879, -0.02230551, 0.007999528, -0.06206681, -0.028820582, 0.00616687, 0.0016019872, -0.0215306, -0.019678399, 0.021782516, 0.00838875, -0.03071301, 0.051114716, 0.07461289, -0.004694868, 0.03344517, -0.013402492, 0.031068956, -0.0064642034, 0.0065336325, 0.0040939264, -0.0059025055, 0.0031639372, -0.06678188, -0.024990749, 0.017469548, -0.07860978, 0.062107254, 0.0016254875, -0.004866095, -0.000497227, -0.043699536, -0.007877377, -0.016148128, 0.043975305, 0.0004564783, -0.034118544, 0.04104323, 0.044226002, -0.059548415, -0.0010648692, -0.037839063, -0.02266013, -0.0064393324, 0.003108287, -0.054755878, -0.04613919, 0.011634995, 0.024233298, 0.02104612, -0.0043809474, -0.008116085, -0.05577426, -0.0016113323, -0.0485395, 0.015793223, 0.011115021, 0.03766905, 0.01871322, -0.011045348, -0.020181147, 0.06311502, -0.0026046354, -0.05173561, -0.0004779752, -0.025194844, -0.011340772, 0.0313944, -0.03540925, 0.028503146, -0.017702432, 0.005789314, 0.12394503, -0.012931669, -0.00061628857, -0.04569108, 0.06504353, 0.018076455, -0.03127659, -0.038669154, -0.041739684, -0.024627214], "index": 0, "object": "embedding"}, {"embedding": [0.047786195, 0.08352973, -0.1390546, -0.051872365, 0.08929118, -0.010951622, 0.02713626, 0.026881361, -0.043898936, -0.011590923, -0.014201768, 0.027333625, 0.06315278, 0.04129167, -0.023867514, -0.011937963, 0.031526357, -0.0359277, -0.015499407, -0.033056803, -0.006723258, -0.039839238, -0.0094952285, -0.038354564, 0.013259577, 0.009712943, 0.004880266, 0.021841533, -0.0031285803, 0.0347964, 0.04283277, -0.044176072, -0.06422112, -0.060943477, -0.05283421, -0.027247952, 0.03290066, 0.03580718, -0.024966877, 0.03324955, 0.07970056, 0.05771106, 0.016543996, -0.025111236, 0.024650518, -0.025837084, 0.0534957, -0.00203836, 0.080581404, -0.09644737, 0.07647293, -0.04716712, 0.019452928, -0.013645595, 0.077590846, 0.050557002, -0.026857851, 0.038227294, -0.055051032, -0.017453138, 0.05314141, 0.04326752, -0.10282046, 0.010858778, -0.023411814, 0.030793699, -0.031973116, 0.014464653, 0.006899576, -0.024938604, -0.0043084132, -0.015468839, -0.039910704, 0.014325829, -0.047575265, 0.020108817, -0.01078495, 0.0047239056, -0.008329823, 0.055618983, 0.0048658657, 0.033435598, 0.022307126, -0.03451269, 0.023724407, -0.015669785, -0.039415445, 0.015968721, -0.08239719, 0.06835072, 0.0321507, -0.041522965, 0.02704702, 0.011415699, -0.0666155, 0.04005045, 0.0006117652, 0.01671893, -0.0397039, 0.009149037, -0.015065656, -0.014958982, 0.012650566, 0.010637115, -0.010691009, 0.029620705, 0.062464166, -0.009109257, -0.016248664, 0.0099259075, 0.0060801893, 0.031396702, -0.029608782, -0.046791464, -0.0015510862, -0.041350722, 0.091400914, 0.0003847161, -0.01619746, 0.02372159, -0.0030599574, -0.035762172, 0.0020627535, -0.0071876105, 0.028303593, 0.019107874, -0.044222485, 0.026149107, -0.048909895, -0.06453058, 0.005298583, 0.003486208, -0.021809751, -0.041460775, 0.046683025, 0.09365509, -0.02586205, 0.016669473, 0.041119516, 0.019686593, 0.00261578, 0.021666972, 0.0026112592, 0.031286765, -0.0039331173, -0.040206857, 0.0054710926, 0.0114836255, -0.024848355, 0.002437919, 0.011824726, 0.02468206, 0.05755693, 0.057508353, 0.011048095, 0.036319017, -0.03273829, 0.0466433, 0.009634551, 0.022917112, 0.021657344, 0.0016194241, -0.02443575, 0.035543427, -0.031596582, -0.012628524, 0.015006683, 0.018685017, 0.00868806, 0.062663, -0.113444515, -0.04003471, 0.0571849, 0.024440043, 0.024794605, -0.009227379, 0.042333346, -0.058399245, 0.035561338, -0.054849755, -0.0015155975, -0.08418743, 0.03689302, -0.030206535, -0.03548758, -0.0120966695, 0.031574804, -0.0026800535, 0.00984831, -0.027292795, 0.0057373554, 0.035771877, -0.026555955, -0.053248808, -0.03632088, -0.0821596, 0.04353999, 0.005373547, 0.05128816, -0.02871392, -0.019220054, 0.014900418, -0.10185389, -0.0049072206, -0.07893869, 0.05838676, -0.030880587, 0.031428058, -0.03558678, -0.032745447, 0.047094923, 0.0020990467, 0.025468998, 0.0040430967, -0.0074505415, -0.02702783, -0.02273377, 0.014533369, -0.013326302, 0.05691577, 0.009084293, 0.017866744, 0.025489664, -0.035602577, 0.065704405, -0.021435572, -0.028413866, 0.016047828, -0.019638427, 0.0059106634, -0.007453174, -0.046640348, 0.024532711, -0.007984212, -0.05450232, 0.04669696, 0.006783689, 0.001390885, 0.0034950757, -0.031516448, 0.036386322, 0.037173275, -0.035231594, -0.02160902, -0.0247572, -0.021085247, -0.026990855, -0.029689534, -0.014591861, 0.03563701, -0.026243294, 0.0026969097, -0.0003357907, -0.024056425, 0.020974386, -0.012241177, -0.0003031552, -0.00909167, 0.037760623, -0.0028356472, 0.020519117, -0.019256935, -0.048061237, -0.028383689, 0.0014152519, -0.044472396, 0.020333355, -0.015109567, 0.04094719, 0.024631675, 0.011493694, 0.0034830163, 0.087236114, 0.046820033, 0.03371453, 0.013521839, -0.06489693, -0.050566934, -0.0111266775, 0.02368177, -0.049447965, -0.06228928, 0.0062220395, -0.012052606, 0.009518903, 0.012421933, -0.009850834, -0.032876227, 0.033891626, -0.055862505, 0.027620396, -0.008044908, -0.02466094, 0.036414914, -0.021837115, 0.005298966, 0.014994942, -0.026858004, 0.03841588, -0.04928004, 0.05334678, 0.025289321, 0.04698788, 0.07394641, -0.02769401, -0.022093726, 0.0019180807, 0.021268733, 0.07506604, -0.030088766, -0.07081765, 0.020067811, -0.04819819, 0.007881947, -0.031204954, -0.007249584, 0.0049559907, 0.024659164, 0.04584714, -0.052237194, 0.00010801211, -0.031784642, -0.010496184, -0.041407898, 0.013076195, 0.02254956, 0.0015201677, -0.0006377148, -0.0029417921, -0.037892982, 0.056867052, 0.020452116, 0.059322514, -0.028228175, -0.0036162694, -0.013410925, 0.008454734, 0.01202544, 0.029152486, -0.0021178436, 0.02861726, -0.019555915, 0.058173914, -0.044573955, -0.022615783, -0.035620257, -0.079109125, -0.06382064, 0.06536487, 0.03857203, -0.022183022, -0.004040479, -0.035499204, -0.04223661, 0.04622082, 0.00056839606, 0.0015513634, 0.022223432, 0.029945418, -0.010958356, 0.012526229, 0.0009598333, -0.013243615, -0.039084613, 0.025567831, 0.03515137, 0.00732686, 0.011226167, -0.0056889215, -0.039716467, 0.016617548, 0.010465404, -0.0027155012, 0.032256693, -0.008497186, 0.07303004, -0.0639684, -0.032897476, -0.012658094, -0.009151125, 0.007671145, -0.024177445, 0.0148651395, -0.024438363, 0.05310356, -0.04720156, 0.066149406, -0.022097163, 0.008807703, 0.016702278, -0.0054960498, -0.07171874, -0.044840913, 0.06812438, 0.012056379, -0.030815354, -0.0028267093, 0.010328807, 0.02490616, 0.04461935, -0.027610328, -0.02365672, 0.008980894, 0.008558363, -0.025431657, -0.012703379, -0.037792105, -0.018829888, 0.037893627, 0.0063046855, 0.017868299, 0.039652176, -0.01526805, -0.020818502, 0.01835681, -0.018711345, 0.050896917, 0.014742913, 0.016908877, -0.030461153, 0.0154143935, 0.013924304, 0.003165862, 0.0055560726, 0.0034365114, 0.018868705, 0.046763126, 0.017103957, 0.006563974, -0.0638682, 0.022447992, 0.020291643, 0.0075749704, 0.0021692107, 0.03742559, 0.005392882, -0.014142728, 0.037124496, -0.015696287, 0.04783306, 0.021999884, -0.03384241, -0.0066300468, 0.004024423, 0.040946946, 0.044322096, 0.07704898, 0.01929965, -0.037172534, 0.05080902, 0.039133515, 0.002135487, 0.015508915, 0.02311153, 0.080243565, -0.00544378, 0.04427909, -0.004956207, 0.0022693244, -0.01758793, 0.045926, -0.025006061, -0.042558454, 0.03842205, 0.01809037, -0.027685877, -0.008315137, -0.033179324, 0.015397622, 0.051507127, -0.054842163, 0.0013309413, 0.012134142, -0.024878113, 0.036176324, -0.012751123, -0.047724277, 0.037089378, 0.0034848037, 0.029749164, 0.008261047, -0.017473774, -0.004734395, -0.059091628, 0.0028011773, 0.044246383, 0.046219394, -0.017592397, 0.0034983172, 0.0059855757, 0.05375236, 0.052853625, -0.0011159697, 0.03510752, -0.016941892, -0.008930022, -0.00022186668, 0.035002384, 0.026499078, 0.01824608, 0.05960519, 0.05852509, 0.038406115, 0.01214143, -0.02814187, -0.026026959, 0.03046139, -0.08213069, -0.05461744, -0.045712687, -0.02401097, 0.019126931, -0.0030355593, 0.028261786, 0.04624995, -0.050752405, 0.04109244, 0.0016325422, -0.025751177, 0.017651822, -0.0024532203, -0.058353283, -0.022906303, -0.043991406, -0.05797727, -0.026277192, 0.0340506, -0.055117473, -0.019928627, -0.049029466, 0.009870912, 0.033778444, -0.047022216, -0.017665356, 0.03524527, -0.034845892, -0.02923699, 0.008648733, -0.009832093, 0.05194449, 0.040944174, -0.0049849167, 0.01574456, 0.010101542, 0.005236673, -0.016850337, 0.036595855, 0.05686019, -0.023822837, -0.099214025, 0.023069607, -0.0469119, 0.019195314, -0.017834514, 0.08187318, 0.030748641, -0.023296194, -0.0068911393, 0.001172806, -0.013768269, 0.02748027, -0.0008802249, 0.0858081, 0.011740195, 0.008638229, -0.009799891, -0.051569995, 0.011530145, 0.005852154, 0.07063325, 0.060459323, -0.03569637, -0.024373489, 0.04668545, 0.0034399163, -0.03982503, -0.025728196, -0.018404273, 0.0041113505, -0.05481143, 0.00689712, -0.043789994, 0.039947703, -0.01900329, -0.016808642, -0.02371707, -0.057818983, -0.05708163, 0.021698747, -0.03313114, -0.014920231, -0.02262276, 0.049020965, 0.03305745, 0.019621216, -0.010842998, 0.00066846516, -0.029624775, -0.008335862, -0.060664553, 0.020153113, 0.027184635, -0.018781, -0.06152546, 0.012765367, 0.04713224, 0.0031023112, 0.03129632, 0.015014469, 0.0024342588, 0.03378188, -0.020714091, -0.025338786, -0.026251841, -0.022486132, -0.05379828, 0.048965782, -0.04700887, -0.07095042, 0.01690457, -0.01100623, -0.02580371, 0.041001666, -0.03499514, -0.0051747854, 0.048243515, -0.04554755, 0.014157106, 0.0010652583, 0.040578242, -0.049873233, 0.00621747, -0.040649865, -0.05014396, -0.037382804, 0.06394427, -0.02422053, -0.028912123, -0.00013209892, 0.011054302, 0.04059782, 0.009903345, -0.022075525, 0.022172878, 0.025019482, -0.011788362, -0.00011542012, 0.050796915, 0.06470735, 0.021190941, 0.05094332, 0.09465994, -0.002364934, -0.054461196, 0.03562616, -0.032033045, 0.018814048, 0.006997511, -0.023943542, -0.027783317, 0.009058001, -0.005365107, 0.011352368, -0.031283263, 0.038168646, -0.028605964, -0.04982409, -0.024364075, -0.0088265035, 0.0010099722, 0.0008929984, 0.018963296, 0.002960083, -0.038293503, 0.018937096, 0.0032669033, 0.06708014, 0.002497212, -0.0011291122, -0.026975492, 0.026588855, -0.0079026185, 0.004886443, 0.0024931845, -0.009259799, -0.0367358, 0.05490717, -0.026937606, -0.0663469, -0.012358412, -0.030723019, -0.052868985, -0.0040329657, -0.0023859085, 0.023827752, 0.0013882535, -0.02288408, 0.032029588, -0.016908033, 0.06778437, -0.04863261, 0.07553774, 0.0011185346, 0.035670653, -0.02149848, 0.056513235, 0.0068086768, -0.011605901, 0.011606019, -0.047586948, -0.0741951, 0.06199303, -0.020273618, 0.06614152, 0.038958147, 0.005987972, 0.018953297, -0.026851937, 0.019539934, 0.0016776584, 0.06580493, -0.0347304, -0.027708413, -0.025663845, 0.019726845, -0.037892137, 0.027067393, -0.03145143, -0.023331517, 0.009212626, -0.032442935, -0.06959219, -0.033430286, 0.051510222, -0.016945705, 0.025338627, -0.021129621, -0.009009409, -0.0478885, -0.012750157, -0.036270842, 0.043775763, -0.037693914, 0.016271895, 0.036725074, 0.0023876578, -0.032222446, 0.044785522, -0.011964213, -0.056537554, 0.06529838, -0.0561622, -0.029266763, 0.02782154, -0.035626385, 0.012683335, -0.013594941, -0.011846663, 0.07593785, -0.023448823, 0.013777459, -0.042271044, 0.04238161, 0.01150256, -0.014416937, -0.086607404, -0.026132086, -0.00013984794], "index": 1, "object": "embedding"}, {"embedding": [0.009977989, 0.06815653, -0.14819986, -0.06404071, 0.07805561, 0.041000906, 0.0032320472, -0.017879896, -0.0066713463, 0.05644504, -0.029122839, 0.022041827, 0.023717904, 0.015530751, 0.04755704, -0.029856844, 0.041481514, -0.016392764, 0.005654617, 0.017755056, 0.011367155, -0.04588454, -0.0003312135, -0.06783385, 0.06332639, 0.02204466, -0.0063033393, 0.039272055, -0.019786725, 0.0018774547, 0.027838062, 0.010129764, -0.048328716, -0.03686031, 0.0074061123, -0.033787493, 0.09691047, 0.016799968, 0.00016796906, 0.029700622, 0.06667958, 0.040580265, 0.0028543745, 0.018995153, 0.011053361, 0.0003772275, 0.021513242, -0.024930568, 0.036010854, -0.07972263, 0.045020223, -0.026231747, 0.0015462424, 0.0011982273, 0.08929213, -0.0036026938, -0.028005695, 0.0029174453, -0.0399687, -0.07591183, 0.045044478, 0.0379795, -0.069752626, 0.0465438, 0.005550606, 0.027724138, -0.025346676, 0.021023495, -0.009219416, -0.034709528, -0.006215655, 0.03312588, 0.016782863, -0.027999742, -0.016018616, 0.007856838, 0.0032843864, -0.04854343, 0.0036968365, 0.062209677, 0.001968108, 0.029992435, 0.029350514, -0.04597929, 0.0048298016, 0.013486244, -0.09050688, 0.03679774, -0.03279508, 0.034862395, -0.023774052, 0.031714875, 0.044764675, 0.0015715942, -0.08383951, 0.019452838, -0.033182807, 0.025371071, -0.0645661, 0.02751658, -0.016053947, -0.024257254, 0.013124238, 0.013629435, -0.017140996, 0.014208442, 0.04340229, -0.047327816, -0.056071874, 0.0069520255, -0.054217476, 0.04364185, 0.0050029675, -0.0040822565, -0.04230849, -0.084521875, 0.065229475, -0.02758324, 0.030123347, 0.053571116, -0.00092008564, -0.044530272, 0.00081514794, 0.0049355454, 0.041218705, -0.017072579, -0.05883411, 0.06737339, -0.0019860275, -0.077531084, -0.004509139, -0.02529936, -0.02121284, -0.0044921455, -0.019114185, 0.058360215, -0.019492496, -0.023613969, -0.004880941, 0.019004956, 0.031718567, 0.006335467, -0.0026988862, 0.018889325, 0.02270529, -0.07012304, 0.017755127, 0.0057268892, -0.051376417, 0.010308235, 0.025659379, 0.041672595, -0.0031092172, 0.01265457, 0.007694291, 0.00917236, -0.018347103, 0.034394816, 0.008381191, 0.026078528, 0.052625235, -0.026065929, -0.012132343, 0.042469133, -0.0214717, 0.019567225, 0.05632203, 0.0030655137, 0.020182798, 0.050619718, -0.07623585, -0.076474264, 0.011913022, -0.00782707, 0.017666152, -0.041109353, -0.01052547, -0.10299457, 0.027747681, -0.04281354, 0.046802163, -0.07581375, 0.05462235, 0.025826424, -0.05417996, 0.0035826329, 0.054140687, -0.022664681, -0.0089427605, -0.041565496, -0.0052871923, 0.04401104, -0.038950536, -0.03775449, -0.0524663, -0.017933944, 0.037618272, -0.023997387, 0.037802782, -0.02281728, -0.04000653, -0.032476943, -0.05813443, 0.025943462, -0.065366775, 0.062223908, 0.013390947, -0.005008548, -0.018149382, -0.018146968, 0.040874425, 0.022761622, 0.030865481, -0.012248325, 0.03343938, 0.0016624914, -0.01900621, 0.01229591, -0.0061759707, -0.012273262, 0.00957333, 0.0075728586, 0.004796846, -0.020146437, 0.03048668, 0.0009765358, -0.089204915, 0.0076415963, -0.05051887, 0.029173998, 0.02341516, -0.041322537, 0.008768551, 0.014780103, 0.021571884, 0.030762505, 0.0032979306, 0.04025221, 0.024906812, -0.013067451, -0.027373532, 0.019103393, -0.013353845, 0.031074546, -0.023704596, -0.020349056, -0.050027367, -0.0058481973, 0.026239287, 0.056222543, -0.0029573436, -0.022898324, -0.015052555, 0.0015396178, 0.023411455, -0.026766397, 0.0054677175, -0.03506974, 0.02353272, 0.018109279, 0.06229017, -0.06836615, -0.0026383975, 0.016310584, -0.020828541, -0.03977806, 0.04382041, -0.019348428, 0.023186147, -0.035734355, 0.0010084849, 0.06382001, 0.051944014, 0.025900736, 0.009072368, 0.02035, -0.005912826, -0.0409533, -0.014339404, -0.034544468, -0.02675013, -0.05643673, -0.037412286, -0.012052126, 0.007814049, 0.030177187, -0.024056578, -0.019997796, -0.020199079, -0.05345932, 0.04835157, -0.005134466, -0.04183984, 0.01908954, -0.028503383, 0.037450824, -0.014594151, -0.0046269814, 0.07541057, 0.0003566511, 0.024962533, 0.012689751, 0.043101877, 0.04871536, 0.0350182, -0.012583128, -0.0034143121, 0.032601412, 0.054630995, 0.027302306, -0.06395464, -0.0007250659, -0.059242442, 0.00855069, 0.0011828878, -0.016915614, 0.026496181, 0.04802881, -0.003419744, -0.004308565, 0.009119495, -0.03134321, -0.026403638, -0.01804867, 0.054172967, 0.032018263, 0.004413309, 0.05225145, 0.010023983, -0.06327918, 0.059885226, 0.02155738, 0.057458106, -0.04934822, -0.047830015, 0.009583073, 0.033286143, 0.018275663, 0.00904048, -0.006131887, 0.103447296, -0.048808925, 0.05720065, -0.050129004, -0.05635215, -0.018441996, -0.009819979, -0.0383674, 0.008236509, 0.017990531, -0.013226251, 0.05955895, 0.0062687728, -0.0169524, 0.031461753, -0.031859715, -0.010011977, 0.036746815, -0.0037631986, 0.024264622, 0.049262226, -0.009995007, 0.027626708, -0.039590772, 0.045686148, 0.031958707, 0.037089065, -0.01942277, 0.01886395, -0.015959956, 0.010244968, -0.049317837, 0.0012500671, 0.029968498, -0.010896259, 0.028548287, -0.029072722, -0.005589502, -0.06030375, 0.015822515, -0.024243137, -0.015949974, -0.01198372, 0.008884029, 0.017085876, -0.032172184, 0.036820054, -0.016365847, 0.009860163, -0.025032958, 0.013996513, -0.05472783, -0.039706465, 0.032079354, 0.009282638, -0.037215788, 0.02830796, -0.002854157, -0.026371446, 0.0323123, -0.029413378, -0.027674146, -0.0014977009, 0.0010509558, -0.028327618, -0.033290543, -0.016579928, -0.03816792, 0.056908965, -0.016563468, 0.016404362, 0.012164182, -0.012351078, -0.05816228, 0.020140013, 0.02254659, 0.0151231075, 0.08203381, -0.052384812, -0.033680342, 0.0063832854, 0.023837544, -0.015964458, 0.010297665, -0.0017696632, 0.00016382607, 0.01603299, 0.047384325, 0.015375416, -0.08777454, 0.044128872, -0.0019917209, 0.043656677, -0.003612799, 0.0028366977, -0.02125056, 0.01582828, 0.04335263, 0.0005519795, 0.006210035, 0.05979486, 0.008657566, -0.044835735, -0.053683, 0.043195963, 0.054449808, 0.08681458, -0.014491711, -0.03678005, 0.07919905, 0.0066807494, -0.011899657, 0.06279076, 0.025761873, 0.06488842, 0.014502867, 0.0145950215, 0.004247882, 0.0144417845, -0.01939946, 0.046480443, -0.015401851, -0.015990533, 0.001615344, 0.0038826691, -0.011051013, -0.009689445, -1.2347096e-05, 0.020008227, -0.00440899, -0.050682485, 0.027539965, -0.041978154, -0.04587846, -0.03185102, -0.0052365563, -0.015297114, 0.010580945, 0.04392371, 0.047978126, 0.03334861, 0.009505319, -0.03699909, -0.026852163, -0.0017115736, 0.015944699, 0.03774526, -0.025183516, -0.017381348, -0.027714726, 0.03136066, 0.04295692, 0.022340778, 0.040297106, -0.033445172, -0.032763638, -0.0041610426, 0.03275634, 0.08491432, 0.03068678, 0.016910395, 0.039961074, 0.032859843, -0.015736926, 0.016544899, -0.02549827, 0.030648055, -0.027561251, -0.004320316, 0.010710699, 0.0026251676, 0.03346602, 0.0061448617, -0.043221094, 0.053408325, 0.0027360742, 0.06449255, 0.012364668, -0.048466314, -0.007113354, 0.004182169, -0.04370544, 0.04317018, -0.07746632, -0.06399742, 0.04585077, 0.05996502, -0.08119896, 0.043672748, -0.039515752, -0.032333277, 0.017267192, -0.09026702, -0.041072827, 0.0012041158, 0.008558915, -0.016383164, 0.05723157, 0.035768375, -0.001898482, 0.03968499, -0.058354747, 0.005534068, 0.02515211, 0.05785674, 6.1383316e-06, 0.025493823, -0.0016057013, 0.0056089903, -0.06333134, 0.045297965, -0.10693441, 0.040043887, -0.036041677, 0.028930834, -0.014376439, -0.030037781, -0.02773788, -0.03954292, -0.06492751, -0.042799167, 0.03086411, 0.11024727, -0.01845463, -0.042971417, -0.04090536, -0.048137106, -0.01536547, 0.029063448, 0.07794801, 0.04267717, -0.05555925, 0.02004312, 0.0323953, 0.012159442, -0.025463307, -0.01473522, -0.015093839, -0.012778119, -0.025348103, 0.0057037245, -0.067212254, -0.0035532024, 0.00819521, 0.011216805, 0.050042048, -0.048646685, -0.022896482, -0.009015524, -0.053374417, -0.00063357526, -0.05497744, 0.0071612694, -0.023022102, 0.0029286414, 0.0071364664, -0.01302603, -0.03448876, 0.014025167, -0.04803165, -0.006150476, -0.023340201, 0.039991196, -0.023404108, 0.00079680193, 0.047403067, 0.020131856, 0.023596559, 0.054307766, -0.057308353, 0.0047637294, 0.02184572, -0.025635136, -0.024950566, 0.035217594, -0.043833204, 0.0366314, -0.051101647, -0.06696991, 0.017061738, -0.05055716, -0.03081378, 0.043369245, -0.0392807, 0.032905404, -0.009215399, -0.0351101, 0.020491017, -0.009532108, 0.04873218, -0.053994793, 0.003916728, -0.005123545, -0.028904708, -0.036363985, 0.021517811, -0.0076898425, 0.00441012, 0.026603727, 0.048204005, 0.04008067, -0.0017822633, -0.015805498, 0.049205344, 0.036389727, -0.017128825, 0.020796794, 0.062254123, 0.006746328, 0.011900444, 0.058956247, 0.06107814, -0.008547538, -0.025737068, 0.05430974, 0.00050956645, 0.005703584, -0.0056498377, -0.023998456, -0.009120056, 0.038837492, -0.009367563, 0.031795852, -0.016241238, 0.008666147, -0.015578837, 0.00676036, -0.0048338063, -0.03334539, 0.022255987, 0.0676996, 0.019852897, -0.0016011924, -0.031228816, 0.0367064, -0.021216104, 0.032281116, 0.016417753, 0.033690713, 0.027194329, 0.023784997, -0.015522765, 0.00047561052, -0.052216955, -0.0098552145, -0.047355376, 0.053853188, -0.0018968796, -0.039697587, -0.00578507, -0.021998046, -0.00769269, -0.002883461, -0.02258748, -0.03848199, 0.008565965, -0.035064492, -0.021529168, -0.00046611385, 0.07897403, -0.025909817, 0.04878023, 0.008965379, -0.002060162, -0.01814662, -0.007353954, 0.03436873, 0.013699095, 0.006566616, -0.04609441, -0.02955607, 0.047301676, -0.053703815, 0.034295306, -0.032901157, -0.0006822823, -0.02916121, -0.018257177, -0.014159929, -0.01519619, 0.06658316, 0.0018966079, -0.053559247, -0.012077704, 0.019082632, 0.00096128637, 0.056790397, -0.05280859, -0.0023528687, -0.015069975, -0.017046513, -0.044047087, -0.02462598, 0.029551346, 0.010140293, 0.020308921, -0.017901074, -0.027606616, -0.03783974, 0.0061176405, -0.041354775, 0.015640806, -0.0141256, 0.0054048467, 0.034730967, -0.04789659, -0.03169192, 0.059197325, -0.0033019402, -0.06892462, 0.029174257, -0.017729223, -0.012738065, -0.0020857046, -0.037468288, 0.019778099, 0.016741976, -0.0040892707, 0.07637437, -0.0065894416, 0.015564577, -0.019109162, 0.035787344, -0.02160523, -0.050620303, -0.11979219, 0.0053711347, -0.049668003], "index": 2, "object": "embedding"}, {"embedding": [0.02788974, 0.09475967, -0.14749722, -0.048063237, 0.02965805, -0.06579463, 0.026943922, -0.030321598, 0.007312401, -0.0022677458, -0.037943564, 0.0059982217, 0.049479846, 0.0012786813, -0.02061335, 0.047599338, -0.031047031, -0.037297055, 0.03611197, -0.01271758, -0.03900345, -0.057424165, -0.045692418, -0.021615567, -0.012266621, -0.013787044, 0.002820167, 0.009910289, 0.057467703, 0.041734666, 0.0447654, -0.018516123, 0.025569381, -0.0392692, -0.06426122, -0.031994324, 0.043674104, -0.017083796, -0.037727803, 0.008823425, 0.063431896, -0.037315436, 0.0032377304, -0.042093072, 0.08590072, -0.008226408, 0.038618933, -0.022969265, 0.08768952, -0.03598898, 0.04282443, -0.011545034, -0.024017395, 0.014004203, 0.06128394, -0.022739097, -0.07658565, 0.06583403, -0.026540795, -0.04941029, 0.1411796, 0.059768096, -0.03016749, 0.021674143, 0.028400848, -0.019162798, -0.034479752, 0.009426984, 0.004250876, -0.04014858, 0.006327918, 0.018253813, 0.017703904, -0.018331746, -0.029047651, 0.006730752, -0.015455998, 0.0078079286, 0.031358887, 0.013739331, 0.01946093, 0.006688241, 0.08749797, -0.09238938, 0.062304642, 0.039783537, 0.013927353, -0.0075035105, -0.027390065, 0.06357149, -0.040795416, 0.03574263, 0.04111787, 0.021268936, -0.051051825, 0.021703122, -0.00051636866, 0.007117175, -0.030281365, -0.009707635, -0.03679819, -0.024080139, -0.058647234, 0.044334795, 0.020477567, -0.011652573, -0.01865116, 0.017557822, -0.027497998, 0.046288274, -0.017135197, 0.0004364222, 9.248143e-05, 0.0046656462, 0.012081883, -0.060907632, 0.10109651, -0.036561575, 0.0075132623, 0.042097688, -0.053699564, 0.028867725, -0.0013004486, -0.015490044, 0.08654454, 0.040929165, -0.05875559, -0.0064161727, 0.01924681, -0.012053178, -0.025626827, -0.020142589, -0.08625902, 0.025219208, 0.04566409, 0.07910895, -0.04843914, -0.00799132, -0.0019619442, 0.02190371, 0.04070262, 0.015917916, -0.029759815, 0.058644038, 0.0098049035, -0.010074691, -0.008486516, -0.042854056, -0.061732307, 0.048653435, 0.022116741, 0.04502648, -0.016174246, 0.068457305, 0.041774742, -0.029286716, -0.046696834, 0.017494584, 0.024846606, 0.014159475, 0.034897324, 0.00025698968, -0.008805642, 0.047299046, 0.011614015, -0.018644538, 0.025693065, 0.060191784, 0.021411877, -0.008573174, -0.028742855, -0.013891911, -0.023370937, 0.032267097, 0.057984795, -0.054827645, 0.050348233, -0.029837798, -0.009541156, -0.0064709787, 0.100304894, -0.078274205, 0.030733045, 0.011627456, -0.0032487998, -0.012754715, 0.029498428, -0.06138638, 0.026826862, -0.0635732, 0.046385597, 0.02208455, -0.060524672, -0.006422482, -0.037300814, -0.021900909, 0.05091324, 0.054052368, -0.004533076, -0.04636611, -0.0017793314, -5.9386316e-06, 0.0035500482, 0.042226437, -0.056029607, 0.042474695, -0.012558005, -0.005279207, 0.011132263, -0.059449792, 0.06620171, -0.060346305, -0.004456114, -0.02274272, 0.055866916, -0.005009739, -0.0068765827, -0.017906737, -0.026620118, 0.021706706, 0.010022694, -0.040973432, 0.068770126, 0.013357222, 0.042558074, 0.0049496284, -0.05638337, 0.031815313, 0.008684407, -0.00027503032, 0.04474666, -0.08068513, 0.052917335, 0.0344208, 0.0069889585, 0.06975585, -0.051173892, -0.011173484, 0.016405271, 0.02520782, 0.036917165, -0.012503568, -0.048507083, -0.040817656, -0.060021754, -0.023581231, -0.018761447, -0.022882668, -0.015619557, 0.006791955, 0.0049059936, -0.013025464, 0.035727765, -0.05889805, 0.007951463, -0.024096629, -0.00914571, 0.018480545, -0.0004337086, 0.009233473, -0.012199652, -0.048972204, 0.030939497, -0.024337841, -0.02127452, -0.027061557, -0.024928886, -0.032552004, 0.029624306, -0.0009386949, 0.040296152, 0.04943133, 0.025478564, 0.075005084, 0.05768047, 0.03807912, -0.017920684, -0.00019963118, 0.0008916611, 0.019113906, 0.03362168, -0.10331618, -0.0619471, -0.01677574, 0.033626124, 0.027852628, -0.03213525, 0.019882735, 0.048357308, 0.011018059, 0.06721917, 0.029677171, -0.0387909, 0.0020962155, 0.021459628, -0.006379185, 0.035640772, 0.0060030487, 0.01953713, -0.02120227, 0.03683007, 0.039505422, 0.066407144, 0.05574815, 0.010147381, 0.01774744, -0.03513357, -0.0098350365, -0.0054343343, -0.01000983, -0.0079013975, -0.033651877, -0.032368507, 0.009581417, -0.03219949, -0.0033426879, 0.039079897, -0.017466879, 0.017603243, -0.031757545, -0.002421313, -0.0015542359, -0.02725631, -0.056056038, 0.019028665, 0.010708316, -0.023610506, 0.018868182, -0.03866812, -0.00945654, 0.0038476656, 0.020592365, 0.06620532, -0.04514405, -0.023862898, -0.025436498, 0.034418337, 0.0009961711, 0.019416625, 0.010424098, 0.024740726, -0.052038897, -0.0014970055, -0.055387165, -0.04450051, -0.0033619332, -0.062981315, -0.0264663, 0.013782096, 0.010322733, -0.022704626, -0.02246384, -0.0141660925, 0.018666666, 0.0004061371, -0.039514888, 0.018350512, 0.087333106, 0.018205969, 0.024305567, 0.014717168, 0.006096483, 0.07468799, -0.032744188, 0.008909184, 0.035847574, 0.029585823, -0.0085934065, -0.013007162, 0.022277365, -0.029343305, 0.035105277, -0.009573136, 0.019576708, -0.017666413, -0.0028256897, -0.06731303, -0.045189742, 0.017277362, 0.014597817, 0.012116139, 0.0037473901, -0.05175529, -0.02787106, -0.005025013, -0.0038484216, 0.0152483545, -0.02748817, -0.014689068, 0.0046682716, 0.013502414, -0.06827016, -0.047519404, -0.001168464, 0.003390034, 0.048451133, 0.01739849, -0.040027097, 0.103144385, 0.03641063, -0.0051389067, -0.07527496, -0.007879692, 0.004008329, 0.003474713, 0.021273768, -0.017996803, -0.06743934, -0.022152409, -0.012776705, 0.00041366476, 0.06580138, -0.035351902, -0.036032066, 0.016986087, -0.027672714, 0.043444313, -0.0022190623, 0.03148279, 0.0013919013, 0.009714946, 0.004091026, -0.03748582, -0.034097586, -0.02883876, 0.013772535, 0.0043810937, 0.06137891, -0.009931636, -0.06152022, 0.025958154, 0.025232244, 0.005574648, -0.04903811, 0.040514395, -0.014817763, 0.08085866, 0.027574312, -0.032902423, 0.006256799, -0.008559325, 0.03262658, 0.05038013, -0.029863717, -0.0013821374, 0.0382111, 0.0015894589, -0.018522754, -0.030096306, -0.043859866, 0.01755686, 0.012313741, 0.080104955, -0.017358439, 0.01351477, -0.0067884345, 0.021213345, 0.06483465, 0.040235925, 0.02899115, 0.039454702, 0.016152153, -0.033932038, 0.017154237, 0.03756969, 0.014564155, -0.0148542505, -0.011807678, 0.030311933, 0.012836768, 0.0051064184, 0.0014470407, 0.009061647, -0.006312863, -0.018430753, -0.044607736, 0.010349641, -0.00071290514, 0.035940792, 0.015301018, -0.005935023, 0.005281372, -0.0017543881, -0.03685991, 0.023593264, -0.016348554, 0.0036526571, -0.05828296, -0.026468633, -0.0062117064, 0.029936083, 0.03910797, -0.018318335, 0.0079184, -0.029203456, 0.021722829, -0.03595087, 0.010793684, 0.01199753, -0.022861872, 0.065703884, 0.07516811, -0.034781445, -0.035373766, -0.0016728804, -0.054380883, 0.016516663, -0.025918704, -0.019027043, -0.026456252, -0.010443513, 0.0061972165, -0.06200038, 0.028219318, 0.03820748, -0.07738717, 0.027570745, 0.019271884, -0.00026385492, 0.053838518, -0.053571507, -0.029585874, 0.016157757, -0.022546114, -0.064362854, 0.01541715, -0.002248893, -0.001534493, 0.013301607, -0.006750673, 0.029816967, 0.058002386, -0.07194799, -0.039307896, -0.015763804, 0.018135076, -0.06003496, 0.0314566, 0.042432617, 0.030541623, -0.06361026, -0.09174577, 0.022719463, 0.029761145, 0.026339222, -0.04943074, -0.004855912, 0.015362537, 0.035254195, -0.04704382, -0.033177204, -0.043470886, 0.029364059, -0.0010455148, 0.09298867, -0.008681101, 0.0006944368, 0.013708839, -0.014944965, 0.03300908, 0.08301691, 0.033129428, 0.057672106, -0.03179122, 0.018965041, 0.03607346, 0.0007204353, -0.03887909, -0.028897908, 0.04782739, 0.025401928, -0.021325147, 0.001232264, -0.011057708, 0.031514157, 0.0052893865, 0.010161096, -0.019441776, -0.017781002, -0.023437075, 0.033231437, 0.005504336, 0.08025804, -0.0088755805, 0.024641791, 0.030358966, -0.079888634, -0.04755462, 0.04199817, -0.034368474, 0.03101101, -0.030630069, 0.027245479, 0.009522402, 0.022439675, 0.015601776, 0.012666071, -0.040723573, -0.011529733, -0.04831144, 0.028607717, 0.019306218, 0.028583815, -0.05914048, 0.042071648, 0.035664625, 0.008316539, 0.048077054, 0.0033592668, -0.07351914, 0.015741272, 0.009433498, -0.034189735, -0.026985599, 0.02332516, 0.0020469949, 0.03185449, -0.004876261, -0.030620381, 0.010382723, -0.03595034, -0.036674667, 0.01684903, -0.0010357988, 0.031703904, 0.009717614, -0.048013024, -0.007295294, 0.026378566, 0.06677892, -0.009359262, 0.01110297, -0.022027096, -0.04660108, -0.042433657, 0.012318265, -0.005332018, -0.052575707, -0.012611002, -0.00025845933, 0.034376312, -0.027911479, 0.0061189253, 0.01990335, 0.028810333, 0.00973074, 0.02115091, -0.039307427, 0.046361778, 0.030393934, 0.023138339, 0.08701819, -0.025109913, -0.056848913, 0.009806355, -0.03333281, -0.04132412, -0.038747128, -0.028940763, -0.027517723, 0.030884119, 0.03499364, -0.017990818, 0.00458583, 0.02160066, 0.004075829, -0.042008072, 0.0061368356, -0.045409456, -0.01692492, 0.035376664, 0.029275896, -0.040675916, -0.03308841, 0.026764868, 0.010497426, 0.0010687707, -0.008167447, -0.022690643, -0.0009138926, -0.0015101188, -0.015235877, 0.015807234, 0.024572298, -0.039288133, -0.013615424, 0.019822676, -0.019418012, -0.018094134, -0.087081224, -0.03475181, -0.03616945, -0.020596595, 0.043502368, -0.018731756, 0.01612614, 0.021960834, -0.035344977, 0.011553568, 0.0630029, -0.038121756, 0.034771454, 0.031654015, 0.028568527, -0.0021144035, -0.027135909, 0.021844156, 0.0037476055, -0.016342545, -0.023428224, -0.018443432, 0.026355332, 0.021674925, 0.039955046, 0.01937281, 0.024149893, -0.025093874, -0.044114172, -0.016617177, -0.0339962, 0.02303064, 0.007475915, -0.027851999, -0.019459067, 0.033225875, 0.0024930162, 0.06245559, -0.039754115, 0.02922063, -0.005342023, -0.0017719178, -0.041733854, -0.027310748, -0.020103566, 0.008597937, -0.034255147, -0.009782949, -0.012306212, -0.053931132, -0.010674516, -0.06855993, 0.008494921, -0.044724118, 0.049520325, -0.002428868, 0.0036114252, -0.017728737, -0.019516623, -0.0114039425, -0.032558165, 0.015624655, -0.03996781, -0.057510618, -0.030995114, -0.003125986, 0.021471059, -0.01798217, 0.0125045385, 0.039601956, 0.015551986, -0.020897169, -0.055132773, 0.059765376, 0.043190263, 0.014273203, -0.071183175, -0.0071136174, -0.019482251], "index": 3, "object": "embedding"}, {"embedding": [0.054220635, 0.08435928, -0.16906945, -0.09528011, 0.062074833, -0.03799164, 0.017672034, 0.011942087, -0.04050711, -0.011411036, 0.014209235, 0.036326937, 0.068479724, -0.008103231, -0.047238108, 0.02352273, 0.018489217, -0.0039640185, -0.045911577, -0.032481574, -0.02271437, -0.049966495, 0.010252245, -0.07068157, 0.018917719, 0.03606792, -0.028623924, -0.0029422913, -0.028461337, -0.0030048694, 0.037205677, -0.09534789, -0.036231328, -0.031427797, -0.04163948, 0.0010018761, 0.028822435, -0.06560055, 0.0062785163, 0.061838783, 0.049336076, -0.041983996, 0.009531272, -0.003087683, 0.040801447, -0.034626316, 0.042144332, -0.02395459, 0.070550926, -0.098351, 0.041038748, 0.01693421, -0.024333509, 0.020955447, 0.048107024, 0.019460674, -0.004379782, 0.06361931, 0.030873392, -0.032525457, 0.08856532, 0.04952488, -0.058564514, 0.03589008, 0.0009512569, -0.028891405, -0.03559774, 0.02631818, 0.00859993, -0.04467153, -0.010336145, -0.022931138, 0.032787394, 0.009606098, -0.010088978, -0.007449116, -0.032456998, -0.03681447, -0.03711882, 0.03406734, 0.028046822, 0.051634695, 0.030773316, -0.0072051054, 0.054155227, 0.0096514, -0.011552065, -0.0019045705, -0.07744467, 0.09519615, 0.0070311027, -0.0065610195, 0.039148252, 0.01128937, -0.056482, -0.007976877, -0.059529435, 0.009759447, -0.06177834, -0.03163417, -0.012065437, 0.0032941578, -0.015371593, -0.04334991, -0.0030059984, 0.0037431195, -0.0057669445, 0.004939268, -0.0055856155, 0.0044567524, -0.0037949325, -0.0009937417, -0.03711151, 0.0017734966, -0.029096441, -0.0544451, 0.08936813, 0.017060477, 0.014092968, 0.022710087, 0.033139028, -0.006670001, -0.009093435, -0.04981794, 0.04430245, 0.06402344, -0.076358125, -0.010887083, -0.029011631, -0.026724534, 0.007732899, 0.012945621, -0.032772485, 0.00793692, 0.021767113, 0.11341899, -0.05499729, -0.011202276, 0.05064385, 0.0022754685, 0.021678789, -0.008953406, -0.046375822, 0.013739103, 0.011688101, -0.040042996, 0.0063713472, -0.022618793, -0.031387556, 0.027764834, -0.023809474, 0.04358514, 0.014933891, 0.029100047, 0.05615493, 0.0029140045, 0.0048309695, -0.03286451, -0.008332182, 0.00095294125, 0.018961655, 0.0069652405, -0.03264646, 0.024657467, -0.013015659, -0.05356519, 0.0435444, 0.03641958, 0.030254558, 0.04667252, -0.06909719, -0.028295025, -0.013279866, 0.015504607, 0.037971206, -0.019151552, 0.06488142, -0.004667254, -0.01930287, 0.002571262, 0.050460212, -0.08947427, 0.013972702, 0.0025468178, -0.025901992, 0.03246831, 0.0058189128, -0.037083387, 0.02324343, -0.07632832, 0.023817606, 0.042520676, -0.036050465, -0.012108207, -0.05442338, -0.029356807, 0.05287786, -0.03240251, 0.03265319, 0.006462476, 0.01536276, -0.006851107, -0.03301542, 0.03611889, -0.036170825, 0.01921889, 0.0194614, 0.022106843, 0.033937454, 0.022680417, 0.06601166, 0.038848955, -0.020485386, 0.0036746424, 0.041807346, -0.0072036777, -0.023629898, 0.001908538, 0.009388799, 0.006771405, 0.018368179, -0.046344027, 0.042170916, -0.045749582, 0.05183618, -0.021001946, -0.015277859, 0.013445255, -0.061627872, 0.047794063, -0.0086988155, -0.02896584, 0.029249994, 0.021954825, 0.016270638, 0.02506461, -0.009639178, 0.054106, -0.047307536, 0.020174062, 0.016667275, 0.036501806, -0.024762135, 0.008139284, -0.065466784, -0.022060987, -0.0016228085, -0.0250128, -0.055884413, 0.061723456, 0.011434956, -0.013118348, 0.06321603, 0.016250595, 0.029206682, -0.02437677, 0.00540513, -0.005401899, 0.05247359, -0.062559545, 0.03474489, 0.026412513, 0.019740758, -0.014160922, -0.02854332, -0.0020708526, 0.028618688, -0.005892255, -0.009987191, -0.026260413, 0.018646823, 0.01827686, 0.035831366, 0.03366341, -0.013466545, 0.04045472, -0.009357041, 0.00051499606, -0.0012938034, 0.063441195, 0.0031535283, -0.1166476, -0.023550415, -0.0528381, -0.020624243, 0.008347591, 0.01519278, -0.013230913, 0.02048678, -0.023950612, 0.048461843, 0.036189403, -0.01601936, -0.02984385, -0.033616204, 0.020923179, 0.044689454, -0.035332557, 0.016481953, -0.043173082, 0.010217438, 0.0022360082, 0.07237972, 0.05807678, -0.010478453, 0.013205032, -0.04855373, 0.011480722, 0.031234793, -0.0051311455, -0.012142231, -0.015923781, 0.010263032, 0.025472067, -0.03011196, 0.010405748, 0.034361925, 0.0073917825, 0.032435495, -0.008155283, -0.0038942324, -0.040552482, -0.019557381, -0.06936986, 0.013486105, 0.045799654, -0.022658253, 0.014357032, -0.022895783, 0.017012803, 0.03653678, -0.0032059797, 0.030360758, -0.044578325, -0.010906682, 0.014278649, -0.0070315152, 0.020172313, 0.038842387, -0.011275103, -0.009450932, -0.031574257, 0.015567575, -0.00072999205, -0.027807897, -0.015022812, -0.06543159, -0.043363128, 0.036462575, 0.037937853, -0.018329669, -0.0056862277, 0.0077321143, -0.032736298, 0.04532476, -0.041987814, 0.011275739, 0.043611683, -0.011850381, 0.0018725186, 0.06676633, 0.008125552, 0.022207288, 0.009246341, 0.015010001, 0.010898503, 0.053148348, -0.017411299, 0.013677556, -0.0068898816, 0.04766274, -0.0033843853, -0.03928002, 0.034316376, -0.009475058, 0.008034838, -0.0773594, -0.008419461, -0.016488481, 0.024460735, 0.010774463, -0.01267744, -0.0035591435, 0.0014104792, 0.008320017, -0.0044090655, 0.031035917, -0.02301983, 0.0008055121, 0.0023967887, -0.021165606, -0.055898115, -0.056166653, 0.012033598, 0.01036913, -0.021041166, 0.08471995, -0.022371018, 0.01064854, 0.029600218, -0.0487945, -0.0632514, 0.013223569, -0.023194611, 4.343664e-05, -0.069669254, -0.047970798, -0.036123473, 0.0047493316, 0.011377197, 0.014443247, 0.045475744, -0.018452745, -0.014147562, 0.01962013, -0.037784427, 0.037843153, 0.003065985, -0.012483004, -0.021166904, 0.034262165, 0.01119371, 0.01301374, -0.0173674, 0.019238723, 0.03296936, 0.08367367, 0.016816316, -0.04991712, -0.06911668, 0.02137332, 0.035839874, 0.045841686, -0.0063056974, 0.01638104, -0.029606963, 0.014418845, 0.000490919, 0.018024296, 0.020738656, 0.049033288, -0.030669078, -0.013953852, -0.020689668, 0.020535974, 0.07231705, 0.05084086, -0.005820981, -0.054017324, 0.0023716446, -0.0087586045, 0.0016839987, 0.011670242, 0.03946331, 0.06144099, 0.03993452, 0.026303958, 0.02572869, 0.06913311, 0.00022238387, 0.022098646, 0.048694726, -0.04758354, -0.008636409, -0.017676415, -0.021157185, 0.0041504744, -0.019775242, 0.04015105, 0.021137137, -0.03174491, -0.030132774, 0.03610298, -0.0016885303, -0.016333608, -0.032879844, 0.025570868, 0.019625226, 0.04862777, 0.017598676, 0.014007889, -0.013521261, -0.028062232, -0.050708856, -0.011337964, 0.051756978, 0.035371114, -0.040406354, 0.015253007, 0.01841094, 0.02469189, -0.0007098324, -0.028184468, 0.07385631, -0.0089877155, -0.0136502525, -0.0023336578, 0.029259218, 0.029020345, 0.02337686, 0.0674777, 0.09758762, 0.0031477571, -0.042816628, -0.018673394, -0.019622741, 0.0134200975, -0.056077164, -0.02443497, -0.010580102, -0.008232231, -0.016516604, -0.04105098, 0.057118353, 0.04136813, -0.079071485, -0.0013330102, -0.01394737, -0.032229055, 0.057515208, -0.03800044, -0.052348208, 0.05488276, -0.037302066, -0.09107684, 0.010937844, -0.026051072, -0.007758881, -0.007981544, -0.01577549, 0.004637806, -0.0056713233, -0.051637467, -0.01949156, -0.0089568375, 0.011290865, -0.029309785, 0.04528055, 0.04678288, 0.006856378, -0.0089439945, 0.004953218, 0.037463162, 0.011217583, 0.014471312, -0.023664145, 0.0053885644, 0.050414573, 0.008634678, -0.10677713, 0.038118318, -0.038965605, 0.040829495, 0.029835492, 0.027723314, -0.04029017, -0.041109618, -0.07933423, -0.014175391, 0.030023169, -0.008368955, 0.015709603, 0.062284343, -0.05901784, -0.017922726, 0.003358594, -0.014268691, 0.03658846, 0.0076963566, 0.016548844, 0.05490985, -0.059048824, -0.024631323, 0.009616913, 0.014744131, -0.03257728, 0.017172683, -0.029322725, -0.046942018, -0.0369698, 0.008799074, -0.037321255, 0.054003384, 0.04706215, 0.026167082, 0.0046934835, -0.062387697, -0.015879087, 0.059994962, -0.08642436, 0.018397024, -0.050200336, 0.036615614, -0.050315473, -0.024251312, 0.0117225405, -0.009232828, -0.0014778366, -0.038187377, -0.05736337, -0.018651012, -0.0028194224, 0.0385485, -0.075876914, 0.031098915, 0.044633582, 0.0071192426, -0.007914286, -0.008992412, 0.011350268, 0.047474228, 0.0053205346, -0.036380596, -0.010068702, 0.025630739, -0.03300204, 0.044869743, 0.007587727, -0.0010761383, -0.042181388, -0.012514731, -0.03267578, 0.014206702, -0.040363576, 0.009846082, -0.03327107, -0.05463936, -0.022141337, 0.02201896, 0.068507604, -0.020231808, 0.012229249, -0.056513987, 0.00915606, -0.013204621, 0.00522038, -0.018860599, -0.04408798, 0.043455925, 0.03646719, 0.04026329, -0.0077806404, -0.054395415, 0.031042892, 0.076762095, -0.011323024, 0.043891173, 0.08225748, 0.026011692, -0.023659216, 0.054637577, 0.09362455, 0.035025474, -0.027524207, -0.029290037, -0.008652128, 0.0056108017, -0.022188414, -0.061071914, 0.00754541, -0.040266942, 0.009022994, -0.0026506532, 0.007542187, 0.029436344, -0.02892879, -0.025953745, 0.00035166662, -0.023719572, -0.054375224, 0.009361125, 0.07147707, -0.012751415, -0.014291206, 0.0072881174, -0.00063760375, 0.032816704, -0.0065809176, -0.033447415, 0.0007593622, 0.033099063, 0.0063865497, 0.014473895, -0.020697488, -0.015518534, -0.06720642, 0.019013146, 0.017207764, -0.033370186, -0.004447882, -0.013499088, -0.0014457399, -0.014445764, 0.037926428, 0.0018309464, 0.056463104, -0.0030862882, -0.022251477, 0.0068545206, 0.04587948, -0.06866357, 0.054265972, 0.021538699, 0.03894622, -0.017740045, 0.012358603, -0.0039270716, 0.01533402, 0.005329779, -0.07649894, -0.035326466, 0.036018547, -0.031090125, 0.04594313, 0.007698968, 0.03995314, -0.009766861, -0.0069122477, -0.0013222861, 0.0132475775, 0.04200432, -0.03039314, -0.027745703, 0.030883942, 0.023198683, -0.022462241, 0.026705917, -0.037653722, -0.014445739, 0.029447503, -0.00022356783, -0.03849494, -0.027143722, 0.044727553, 0.0019400439, -0.023879128, -0.009385825, -0.013869273, -0.022729924, -0.0122450795, -0.09962149, -0.023571216, -0.034934733, 0.027842319, -0.01982946, -0.009220047, 0.0076564406, 0.062303342, 0.00614408, -0.052730005, 0.034793902, -0.081132784, -0.0061336225, 0.0024344055, -0.033003844, -0.0112612555, 0.04606753, 0.03507537, 0.08699788, -0.02929258, 0.0023318639, -0.018761778, 0.07106376, 0.037602715, -0.016382221, -0.0154796075, -0.0134846475, -0.012241711], "index": 4, "object": "embedding"}, {"embedding": [0.05261834, 0.04213624, -0.16220425, -0.13029186, 0.09330993, -0.005521069, 0.019371241, 0.027164694, -0.028051607, 0.043634944, -0.019197145, 0.04708044, 0.07266067, -0.008856415, 0.018092202, 0.027312204, -0.07489836, -0.021516435, -0.0077242963, -0.034769587, 0.003032736, -0.023338942, -0.00564454, -0.026665792, 0.0315085, 0.0030425612, -0.025500942, 0.02886367, 0.0133917285, 0.04214106, 0.038754527, -0.04805686, -0.0064433725, -0.04752472, -0.023165783, -0.040643983, 0.043509882, 0.028938958, 0.020885943, 0.00471092, 0.052439034, -0.04586991, 0.0053308415, -0.025488004, -0.009090989, 0.012334616, 0.07485354, -0.019824864, 0.049833484, -0.031572785, 0.035228904, 0.0035111695, 0.01485993, 0.0054602437, 0.116953194, 0.038139716, -0.073307276, 0.05399963, 0.02254938, -0.010172582, 0.04385533, 0.029214956, -0.07586877, 0.056820136, -0.028556656, -0.020563856, -0.04660874, -0.0032732715, -0.002658116, -0.035360035, 0.017647484, 6.79694e-07, -0.031448957, 0.036075335, -0.028867988, 0.018782362, -0.032800876, 0.016670058, -0.009318292, 0.029088227, -0.022537885, -0.004854948, 0.041457154, -0.031747695, 0.039592057, 0.0412844, -0.06510135, 0.0008555417, -0.028327163, 0.06478823, -0.017058734, 0.0034996816, 0.06837216, 0.043364067, -0.046575814, 0.025895463, -0.010235796, 0.023817137, -0.038247436, -0.009157505, -0.013754801, 0.030222721, -0.010620332, -0.05826131, 0.0015896442, 0.05382924, 0.00042386985, -0.009246649, 0.030499786, 0.039032497, -0.01744685, 0.019240908, -0.047542866, -0.01058345, -0.056406934, -0.05418415, 0.079863615, -0.011919879, 0.014325448, -0.026095353, -0.0038200736, -0.028887402, 0.021332813, -0.026274245, 0.045353048, 0.035499085, -0.071698904, 0.043252066, 0.018907474, -0.032957364, 0.023701593, -0.00064462196, -0.03959106, 0.017984867, 0.008784629, 0.113957666, -0.03583865, -0.043333296, 0.026494041, 0.053241637, -0.008048623, 0.018194867, -0.0027142172, -0.005612065, 0.039065067, -0.064840496, 0.023972953, -0.012405733, -0.022937775, 0.03098587, 0.023031909, 0.024982648, 0.0126793245, 0.024744865, 0.038792808, -0.01247719, 0.0010842724, -0.010703097, -0.0016327893, -0.0015471113, 0.0067231595, 0.0017903065, 0.00034935612, 0.04285162, -0.01935718, -0.0075747664, 0.030676246, 0.016441917, 0.03579045, 0.04559717, 0.00032971607, -0.033487253, 0.0035205858, -0.00079545984, 0.04543527, 0.022447564, 0.07045713, -0.025571829, -0.032531463, -0.007216049, 0.06706446, -0.04422995, 0.036410898, -0.022985036, -0.0038774565, -0.0041947663, 0.029226938, 0.016633963, 0.031272214, -0.012489296, -0.0052723386, 0.022627966, -0.04217533, -0.061596077, -0.025386902, -0.04432727, 0.07156416, 0.020227358, 0.008091612, 0.004911293, 0.007145592, -0.02305994, -0.041167192, 0.02390172, 0.0021538883, 0.054191086, -0.01389722, 0.030160997, -0.021680258, 0.0051364833, 0.023705635, 0.016060278, 0.033805203, -0.0033987116, 0.0049081743, 0.028377121, -0.016899245, -0.0157321, -0.032296766, 0.01552019, 0.077859946, -0.0029640489, 0.06664575, 0.022788508, 0.006800466, 0.0046824277, 0.0034620191, 0.014336944, -0.04402656, 0.014793395, -0.024394186, -0.029662365, 0.029895207, -0.011182336, -0.033143178, 0.038044233, -0.045773827, 0.071812786, -0.008821066, 0.01683597, 0.0701688, 0.07830291, -0.03571709, -0.018395944, -0.049891837, -0.0113194445, -0.019121211, -0.0012094793, 0.0062493, 0.045228135, -0.041603293, 0.018072454, 0.032915924, -0.041417196, 0.049150135, 0.0021980111, -0.021030053, -0.021631211, 0.03526001, 0.020902779, 0.028321277, -0.012250059, 0.013599469, -0.013674212, -0.010883121, -0.03570726, 0.018876834, 0.00054497895, 0.016491856, -0.0055384426, 0.03173504, 0.039739676, 0.042847667, 0.05256096, 0.039631236, 0.009226279, -0.007329918, 0.003185186, -0.018330228, -0.011276393, -0.021821806, -0.06880973, -0.05478832, -0.02720455, -0.020773828, 0.020571446, -0.03171297, -0.01821622, 0.038623262, -0.017946381, 0.018850539, 0.011110209, -0.025869075, -0.019302411, -0.029723363, 0.0385671, 0.032728154, -0.003934258, 0.02794477, -0.03224097, 0.026609633, 0.019607306, 0.031369466, 0.077593155, 0.019277383, 0.025985671, -0.019813705, 0.0024808815, -0.007437343, -0.027199695, -0.050957832, 0.018667672, -0.028397884, 0.060518675, -0.044149317, -0.033614285, 0.014052836, -0.004546921, 0.044649545, -0.043248888, 0.0019488976, -0.0597033, 0.01663117, -0.01970944, 0.0052851653, 0.028109835, 0.020171734, 0.0033997425, -0.028291186, -0.025973983, 0.072693706, 0.02062804, 0.035223655, -0.021606226, -0.073673435, -0.04179984, -0.077205144, -0.03970683, 0.016302612, -0.021976024, 0.015387748, 0.0138211725, 0.049846787, -0.046156812, -0.021176983, -0.00061911053, -0.0550399, -0.04856657, 0.016133275, 0.021675529, -0.032405023, -0.03286004, -0.020849101, -0.025930744, 0.069533624, 0.007513885, 0.012415235, 0.033262666, 0.04368962, -0.0038781618, 0.04943102, -0.0404332, 0.0347974, -0.040508308, 0.012825151, -0.010877666, 0.028865846, -0.00867611, -0.014813938, 0.013496333, 0.014119978, -0.009902356, -0.014024366, 0.03457606, -0.031018041, 0.0069645075, -0.030665556, -0.023608912, -0.04557665, -0.0004580861, -0.022176374, -0.042979736, 0.0031003547, -0.028808484, 0.0053591607, -0.011953472, 0.051737122, -0.03211873, -0.02441157, -0.0035123657, 0.012784092, -0.04909651, -0.04612679, 0.016097002, 0.010399188, -0.017837662, 0.039552525, -0.026471885, 0.003915015, 0.061785735, -0.05132095, -0.013718683, 0.03529649, 0.026314197, -0.018956667, -0.009450733, -0.023066781, -0.007576854, 0.026111824, 0.013559245, -0.01839908, 0.041344993, 0.012704818, -0.08151379, 0.019717459, 0.024349013, -0.009015067, 0.03465306, -0.015854483, 0.035091534, 0.0034452702, 0.046496823, -0.005691372, 0.0142069785, -0.02865029, -0.0031358234, 0.01671528, 0.046756357, 0.022206051, -0.05472054, 0.052943595, 0.005600814, 0.039114106, 0.00066940195, 0.020522429, -0.016670154, -0.017785672, 0.055690166, -0.028754609, 0.012793376, 0.041735407, -0.026379684, -0.048223518, -0.02364668, 0.039809335, 0.053041216, 0.029091557, 0.0082331225, -0.100905344, 0.018246144, 0.02599198, 0.024863329, 0.018884482, 0.008533842, 0.09409426, -0.045821022, 0.021333937, 0.010039288, 0.048750907, 0.05135055, 0.017358918, 0.05106965, -0.07166517, 0.03769673, -0.025760807, -0.037351962, -0.0345431, -0.025988301, 0.05530944, 0.047001693, -0.040094953, -0.019423017, 0.04953526, -0.0014247576, 0.0046769795, 0.009842014, -0.028010856, -0.039280385, 0.04518277, 0.02315945, 0.03411572, -0.032171883, -0.00862248, -0.055821877, 0.028685203, 0.080379404, 0.07160032, -0.020369552, -0.008057853, 0.019114224, 0.055287104, 0.022559036, -0.0058039823, 0.023307389, -0.05296998, -0.01480893, -0.02343903, 0.026241973, -0.0013436179, 0.009292888, 0.03747496, 0.04952517, 0.0018397596, 0.00015579423, -0.021759396, -0.035853192, -0.005589161, -0.059357643, -0.07524341, 0.028664103, -0.013251194, 0.04207252, -0.031580437, 0.008773035, 0.045830335, -0.049382012, 0.026571434, 0.028114842, -0.060262196, 0.0065760724, 0.0064507513, -0.054923307, 0.023488812, -0.03618243, -0.06542511, 0.010902113, 0.012640021, -0.08193512, 0.029730516, -0.061634075, 0.01437284, 0.021230213, -0.04715157, -0.012367389, -0.009141726, 0.013561912, -0.011083002, -0.010560564, 0.039377663, 0.052973703, 0.016086541, 0.023502706, 0.009376585, 0.036578204, 0.031350292, -0.029253762, -0.028626604, 0.0297038, -0.009535236, -0.11220298, 0.021176565, -0.0964432, 0.01722262, -0.02589882, 0.029659633, -0.023914598, -0.039865136, -0.042666674, 0.0025829005, 0.039241567, -0.033150434, 0.0019203427, 0.08119362, -0.0565737, -0.016672486, -0.014549584, 0.019068116, 0.021272147, 0.008231029, 0.03471913, 0.04614869, -0.051539246, 0.031501606, 0.03235896, 0.012410923, -0.013292306, 0.021698855, -0.04229174, -0.083410494, -0.03111287, 0.0077703474, -0.0050994246, -0.013682523, 0.006478927, 0.006022433, 0.038934853, -0.051786147, -0.06240831, 0.04905808, -0.005869174, -0.019667145, 0.015516567, -0.0174459, -0.06535923, 0.013839861, 0.001293905, -0.009423563, -0.029347952, -0.033102892, -0.07236647, 0.028514648, 0.024626471, 0.05671979, -0.056807667, 0.007402019, 0.052464712, -0.023222141, 0.013045281, 0.025854385, 0.0053348904, -0.0012204454, -0.020356422, -0.01770076, -0.007858004, 0.06131652, -0.06925215, 0.049029704, -0.0026697016, -0.09678795, -0.01765555, -0.038442302, -0.030311044, 0.020620164, -0.049308203, 0.0002079111, 0.039500345, -0.0011682347, 0.005060792, 0.01748322, 0.009011397, -0.09797569, 0.0058485316, -0.021080619, -0.0383528, -0.04746719, 0.0474078, -0.023626097, -0.011249674, 0.014674252, 0.017299157, -0.009464885, -0.013141276, -0.0005968946, 0.0059934705, 0.0052552195, -0.0010155013, 0.041779064, 0.0842318, 0.0008144693, 0.004698084, 0.03128108, 0.09860679, -0.01852294, -0.068995, -0.025689011, 0.045254704, -0.0064004683, 0.020792382, 0.007434885, -0.026114527, -0.006355586, -0.035448812, -0.028580654, -0.034677003, 0.03604563, -0.026818996, -0.031459372, -0.038721006, -0.014804999, -0.053640824, -0.0051063416, 0.0030931267, -8.704206e-05, -0.022876682, 0.042053778, 0.010433905, 0.03675822, 0.059532017, -0.031841867, -0.005398338, 0.028013606, -0.0035499649, -0.018775482, -0.0644458, -0.023356851, -0.0674125, 0.02602435, -0.011046518, -0.018218417, -0.028229509, -0.024438607, -0.04439319, -0.013887673, 0.01521614, 0.023117455, 0.063155614, -0.0028393532, -0.01991371, 0.053759508, 0.072372586, 0.010770441, 0.018937716, 0.045388054, 0.011255057, -0.0002718891, 0.0086763725, 0.009836797, 0.009234432, -0.0009109403, -0.051449902, -0.028711114, 0.006568697, -0.016869936, 0.07165783, 0.011961555, 0.0051886993, -0.040199228, -0.0061693015, 0.010787098, -0.033667594, 0.01739997, -0.029969744, -0.044369314, 0.0064978693, 0.020139603, -0.04668811, 0.018401043, -0.013977605, -0.016277133, -0.0027741382, -0.0101416735, -0.041783866, -0.033308905, 0.021016374, -0.0036979008, 0.002655962, -0.07323971, -0.0247662, -0.06669505, 0.016196402, -0.045022734, 0.028682383, -0.004307738, 0.0039211204, 0.018492881, -0.009029834, -0.06580874, 0.021809759, 0.0016950864, -0.054110914, 0.046228018, -0.025490794, -0.035864744, 0.018035214, -0.009823763, 0.038790286, -0.0044595124, 0.03327301, 0.08401651, -0.041830517, -0.0044788565, -0.022963535, 0.055756725, 0.047991984, -0.038042076, -0.045350447, -0.034235418, 0.026775554], "index": 5, "object": "embedding"}], "model": "nomic-embed-text:v1.5", "object": "list", "usage": {"prompt_tokens": 7114, "total_tokens": 7114}}, "input": {"input": [" distributions.\n7.2.1\nImportance of Cross-Entropy for LLM Training and Evaluation\nCross-entropy is crucial for training and fine-tuning LLMs. It serves as a loss function, guiding the model\nto produce high-quality predictions by minimising discrepancies between the predicted and actual data.\nIn LLMs, each potential word functions as a separate class, and the models task is to predict the next\nword given the context. This task is inherently complex, requiring the model to understand syntax,\nsemantics, and context deeply.\n7.2.2\nBeyond Cross-Entropy: Advanced LLM Evaluation Metrics\nWhile cross-entropy remains fundamental, evaluating LLMs effectively necessitates additional metrics\ntailored to various aspects of model performance. Here are some advanced metrics employed in LLM\nevaluation:\nPerplexity\nPerplexity measures how well a probability distribution or model predicts a sample. In the context of\nLLMs, it evaluates the models uncertainty about the next word in a sequence. Lower perplexity indicates\nbetter performance, as the model is more confident in its predictions.\n57\nFactuality\nFactuality assesses the accuracy of the information produced by the LLM. It is particularly important for\napplications where misinformation could have serious consequences. Higher factuality scores correlate\nwith higher output quality.\nLLM Uncertainty\nLLM uncertainty is measured using log probability, helping to identify low-quality generations. Lower\nuncertainty indicates higher output quality. This metric leverages the log probability of each generated\ntoken, providing insights into the models confidence in its responses.\nPrompt Perplexity\nThis metric evaluates how well the model understands the input prompt.\nLower prompt perplexity\nindicates a clear and comprehensible prompt, which is likely to yield better model performance.\nContext Relevance\nIn retrieval-augmented generation (RAG) systems, context relevance measures how pertinent the re-\ntrieved context is to the user query. Higher context relevance improves the quality of generated responses\nby ensuring that the model utilises the most relevant information.\nCompleteness\nCompleteness assesses whether the models response fully addresses the query based on the provided\ncontext. High completeness ensures that all relevant information is included in the response, enhancing\nits utility and accuracy.\nChunk Attribution and Utilisation\nThese metrics evaluate how effectively the retrieved chunks of information contribute to the final response.\nHigher chunk attribution and utilisation scores indicate that the model is efficiently using the available\ncontext to generate accurate and relevant answers.\nData Error Potential\nThis metric quantifies the difficulty the model faces in learning from the training data. Higher data\nquality results in lower error potential, leading to better model performance.\nSafety Metrics\nSafety metrics ensure that the LLMs outputs are appropriate and non-harmful. These are included in\nthe final sections of the chapter.\nIntegrating these advanced metrics provides a holistic view of LLM performance, enabling developers to\nfine-tune and optimise models more effectively. By employing a metrics-first approach, it is possible to\nensure that LLMs not only produce accurate and high-quality outputs but also do so consistently and\nreliably across diverse applications1.\n7.3\nUnderstanding the Training Loss Curve\nThe training loss curve plots the loss value against training epochs and is essential for monitoring model\nperformance.\n1https://www.rungalileo.io/blog/metrics-first-approach-to-llm-evaluation\n58\n7.3.1\nInterpreting Loss Curves\nAn ideal training loss curve shows a rapid decrease in loss during initial stages, followed by a gradual\ndecline and eventual plateau. Specific patterns to look for include:\n1. Underfitting: High loss value that does not decrease significantly over time, suggesting the model\ncannot learn the data.\n2. Overfitting: Decreasing training loss with increasing validation loss, indicating the model mem-\norises the training data.\n3. Fluctuations: Significant variations may indicate a high learning rate or noisy gradients.\nFigure 7.1: Example training loss curve showing the decline in loss over iterations during the fine-tuning\nof Llama2 13B on a financial Q/A dataset. The curve illustrates the effectiveness of the fine-tuning\nprocess in reducing the loss and improving model performance.\n7.3.2\nAvoiding Overfitting\nTechniques to prevent overfitting include:\n1. Regularisation: Adds a penalty term to the loss function to encourage smaller weights.\n2. Early Stopping: Stops training when validation performance no longer improves.\n3. Dropout: Randomly deactivates neurons during training to reduce sensitivity to noise.\n4. Cross-Validation: Splits data into multiple subsets for training and validation to assess model\ngeneralisation.\n5. Batch Normalisation: Normalises inputs to each layer during training to stabilise the learning\nprocess.\n6. Larger Datasets and Batch Sizes: Reduces overfitting by increasing the amount of diverse\ndata and batch sizes.\n59\n7.3.3\nSources of Noisy Gradients\nNoisy gradients are common during the training of machine learning models, including LLMs. They arise\nfrom variability in gradient estimates due to stochastic gradient descent and its variants. Strategies to\nmanage noisy gradients include:\n1. Learning Rate Scheduling: Gradually decreasing the learning rate during training can reduce\nthe impact of noisy gradients.\n2. Gradient Clipping: Setting a threshold for gradient values prevents large updates that can\ndestabilise training.\n7.4\nRunning Validation Loops\nValidation loops provide an unbiased evaluation of model performance. Typical steps include:\n1. Split Data: Divide the dataset into training and validation sets.\n2. Initialise Validation: Evaluate the model on the validation set at the end of each epoch.\n3. Calculate Metrics: Compute relevant performance metrics, such as cross-entropy loss.\n4. Record", ".\n2. Gradient Clipping: Setting a threshold for gradient values prevents large updates that can\ndestabilise training.\n7.4\nRunning Validation Loops\nValidation loops provide an unbiased evaluation of model performance. Typical steps include:\n1. Split Data: Divide the dataset into training and validation sets.\n2. Initialise Validation: Evaluate the model on the validation set at the end of each epoch.\n3. Calculate Metrics: Compute relevant performance metrics, such as cross-entropy loss.\n4. Record Results: Log validation metrics for each epoch.\n5. Early Stopping: Optionally stop training if validation loss does not improve for a predefined\nnumber of epochs.\n7.5\nMonitoring and Interpreting Results\nMonitoring validation results involves analysing trends in validation metrics over epochs. Key aspects\ninclude:\n1. Consistent Improvement: Indicates good model generalisation if both training and validation\nmetrics improve and plateau.\n2. Divergence: Suggests overfitting if training metrics improve while validation metrics deteriorate.\n3. Stability: Ensure validation metrics do not fluctuate significantly, indicating stable training.\n7.6\nHyperparameter Tuning and Other Adjustments\nFine-tuning involves adjusting key hyperparameters to achieve optimal performance. Important hyper-\nparameters include:\n1. Learning Rate: Determines the step size for updating model weights. A good starting point is\n2e-4, but this can vary.\n2. Batch Size: Larger batch sizes lead to more stable updates but require more memory.\n3. Number of Training Epochs: Balancing the number of epochs ensures the model learns suffi-\nciently without overfitting or underfitting.\n4. Optimiser: Optimisers like Paged ADAM optimise memory usage, advantageous for large models.\nOther tunable parameters include dropout rate, weight decay, and warmup steps.\n7.6.1\nData Size and Quality\nThe efficacy of LLMs is directly impacted by the quality of their training data. Ensuring that datasets\nare clean, relevant, and adequate is crucial. Data cleanliness refers to the absence of noise, errors, and\ninconsistencies within the labelled data. For example, having a phrase like This article suggests. . . \nmultiple times in the training data can corrupt the response of LLMs and add a bias towards using this\nspecific phrase more often and in inappropriate situations.\n60\n7.7\nBenchmarking Fine-Tuned LLMs\nModern LLMs are assessed using standardised benchmarks such as GLUE, SuperGLUE, HellaSwag,\nTruthfulQA, and MMLU (See Table 7.1). These benchmarks evaluate various capabilities and provide\nan overall view of LLM performance.\nBenchmark\nDescription\nReference URL\nGLUE\nProvides a standardised set of diverse NLP tasks to\nevaluate the effectiveness of different language mod-\nels\nSource\nSuperGLUE\nCompares more challenging and diverse tasks with\nGLUE, with comprehensive human baselines\nSource\nHellaSwag\nEvaluates how well an LLM can complete a sentence\nSource\nTruthfulQA\nMeasures truthfulness of model responses\nSource\nMMLU\nEvaluates how well the LLM can multitask\nSource\nIFEval\nTests a models ability to follow explicit instructions,\nfocusing on formatting adherence\nSource\nBBH (Big Bench Hard)\n23 challenging tasks from the BigBench dataset to\nevaluate LLMs using objective metrics\nSource\nMATH\nCompilation of high-school level competition prob-\nlems formatted using LaTeX and Asymptote\nSource\nGPQA\nChallenging\nknowledge\ndataset\nwith\nquestions\ncrafted by PhD-level domain experts\nSource\nMuSR\nDataset with complex problems requiring models to\nintegrate reasoning with long-range context parsing\nSource\nMMLU-PRO\nRefined version of MMLU with higher quality and\nmore challenging multiple-choice questions\nSource\nARC\nMeasures machine reasoning with a dataset of grade-\nschool science questions\nSource\nCOQA\nA dataset for building conversational question-\nanswering systems\nSource\nDROP\nEvaluates the ability to perform discrete reasoning\nover paragraphs of text\nSource\nSQuAD\nA reading comprehension dataset for evaluating\nmodels ability to answer questions based on pas-\nsages of text\nSource\nTREC\nA benchmark for evaluating text retrieval method-\nologies\nSource\nWMT\nA dataset and benchmark for evaluating machine\ntranslation models\nSource\nXNLI\nA dataset for evaluating cross-lingual language un-\nderstanding\nSource\nPiQA\nA dataset for evaluating models understanding of\nphysical interactions\nSource\nWinogrande\nA large-scale dataset for evaluating commonsense\nreasoning\nSource\nTable 7.1: Detailed Overview of Benchmark Datasets Used for Evaluating Language Model Performance.\nAs LLMs evolve, so do benchmarks, with new standards such as BigCodeBench challenging current\nbenchmarks and setting new standards in the domain. Given the diverse nature of LLMs and the tasks\nthey can perform, the choice of benchmarks depends on the specific tasks the LLM is expected to handle.\nFor generic applicability, various benchmarks for different downstream applications and reasoning should\nbe utilised. For domain/task-specific LLMs, benchmarking can be limited to relevant benchmarks like\nBigCodeBench for coding.\n61\n7.8\nEvaluating Fine-Tuned LLMs on Safety Benchmark\nThe safety aspects of Large Language Models (LLMs) are increasingly scrutinised due to their ability\nto generate harmful content when influenced by jailbreaking prompts. These prompts can bypass the\nembedded safety and ethical guidelines within the models, similar to code injection techniques used in\ntraditional computer security to circumvent safety protocols. Notably, models like ChatGPT, G", "\nBigCodeBench for coding.\n61\n7.8\nEvaluating Fine-Tuned LLMs on Safety Benchmark\nThe safety aspects of Large Language Models (LLMs) are increasingly scrutinised due to their ability\nto generate harmful content when influenced by jailbreaking prompts. These prompts can bypass the\nembedded safety and ethical guidelines within the models, similar to code injection techniques used in\ntraditional computer security to circumvent safety protocols. Notably, models like ChatGPT, GPT-\n3, and InstructGPT are vulnerable to such manipulations that remove content generation restrictions,\npotentially violating OpenAIs guidelines. This underscores the necessity for robust safeguards to ensure\nLLM outputs adhere to ethical and safety standards.\nDecodingTrust [79] provides a comprehensive evaluation of the trustworthiness of LLMs, notably com-\nparing GPT-4 with GPT-3.5 (ChatGPT). This evaluation spans several critical areas:\n1. Toxicity: Optimisation algorithms and generative models are employed to create challenging\nprompts that test the models ability to avoid generating harmful content.\n2. Stereotype Bias: An array of demographic groups and stereotype topics are utilised to assess\nmodel bias, helping to understand and mitigate prejudiced responses.\n3. Adversarial Robustness: The resilience of models against adversarial attacks is tested by chal-\nlenging them with sophisticated algorithms intended to deceive or mislead.\n4. Out-of-Distribution (OOD) Robustness: Models are evaluated on their ability to handle\ninputs that differ significantly from their training data, such as poetic or Shakespearean styles.\n5. Robustness to Adversarial Demonstrations: Demonstrations that contain misleading infor-\nmation are used to test the models robustness across various tasks.\n6. Privacy: Various levels of privacy evaluation assess how well models safeguard sensitive informa-\ntion during interactions and understand privacy-related contexts.\n7. Hallucination Detection: Identifies instances where the model generates information not grounded\nin the provided context or factual data. Lower hallucination rates improve the reliability and trust-\nworthiness of the LLMs outputs.\n8. Tone Appropriateness: Assesses whether the models output maintains an appropriate tone for\nthe given context. This is particularly important for applications in customer service, healthcare,\nand other sensitive areas.\n9. Machine Ethics: Ethical assessments involve testing models with scenarios that require moral\njudgments, using datasets like ETHICS and Jiminy Cricket.\n10. Fairness: The fairness of models is evaluated by generating tasks that vary protected attributes,\nensuring equitable responses across different demographic groups.\nThe dataset employed for evaluating the aforementioned eight safety dimensions can be found here.\nIn partnership with HuggingFace, the LLM Safety Leaderboard utilises DecodingTrusts framework to\nprovide a unified evaluation platform for LLM safety.\nThis allows researchers and practitioners to\nbetter understand the capabilities, limitations, and risks associated with LLMs. Users are encouraged to\nsubmit their models to HuggingFace for evaluation, ensuring they meet the evolving standards of safety\nand reliability in the field.\n7.9\nEvaluating Safety of Fine-Tuned LLM using AI Models\n7.9.1\nLlama Guard\nLlama Guard 2[80] is a safeguard model built on LLMs for managing risks in conversational AI applica-\ntions. It effectively categorises both input prompts and responses from AI agents using a detailed safety\nrisk taxonomy tailored to identify potential legal and policy risks in AI interactions. It utilises a detailed\nsafety risk taxonomy designed to identify and manage potential legal and policy risks in interactions\ninvolving conversational AI. This taxonomy enables effective classification in areas such as:\n Violence & Hate, addressing content that could incite violent acts or discrimination.\n62\n Sexual Content, targeting sexually explicit material or behaviour, especially involving minors.\n Guns & Illegal Weapons, concerning the promotion or instruction of illegal armaments.\n Regulated or Controlled Substances, covering illegal drugs and other controlled substances.\n Suicide & Self-Harm, aimed at content that could encourage self-destructive behaviour.\n Criminal Planning, for content that could assist in planning or executing criminal activities.\nThe core of Llama Guard 2 is its robust framework that allows for both prompt and response classifica-\ntion, supported by a high-quality dataset that enhances its ability to monitor conversational exchanges.\nOperating on a Llama2-7b model, Llama Guard 2 has been instruction-tuned to deliver strong perfor-\nmance on benchmarks like the OpenAI Moderation Evaluation dataset and ToxicChat, where it matches\nor surpasses the capabilities of existing content moderation tools.\nThe model supports multi-class classification and generates binary decision scores. Its instruction fine-\ntuning allows for extensive customisation of tasks and adaptation of output formats. This feature enables\nusers to modify taxonomy categories to align with specific use cases and supports flexible prompting\ncapabilities, including zero-shot and few-shot applications. The adaptability and effectiveness of Llama\nGuard make it a vital resource for developers and researchers. By making its model weights publicly\navailable, Llama Guard 2 encourages ongoing development and customisation to meet the evolving needs\nof AI safety within the community.\nLlama Guard 3 represents the latest advancement over Llama Guard 2, having been fine-tuned on the\nLlama 3 8b model. The key difference between the two versions is that Llama Guard 3 expands upon\nthe capabilities of Llama Guard 2 by introducing three new categories: Defamation, Elections, and\nCode Interpreter Abuse.\nPython Library: Llama Guard 3 is accessible via HuggingFaces AutoModelForCausalLM.2 A detailed\ntutorial is available at this link. Please note that access to the model requires submitting a request", "-tuned on the\nLlama 3 8b model. The key difference between the two versions is that Llama Guard 3 expands upon\nthe capabilities of Llama Guard 2 by introducing three new categories: Defamation, Elections, and\nCode Interpreter Abuse.\nPython Library: Llama Guard 3 is accessible via HuggingFaces AutoModelForCausalLM.2 A detailed\ntutorial is available at this link. Please note that access to the model requires submitting a request to\nHugging Face with the user details. Additionally, the model weights can be downloaded from the Meta\nplatform by providing user details, and the link can be found here.\nThe prompt formats for these two models also differ, with the specific formats for Llama Guard 2 available\nhere and Llama Guard 3 is accessible here.\n7.9.2\nShield Gemma\nShieldGemma [81] is an advanced content moderation model built on the Gemma2 platform, designed\nto enhance the safety and reliability of interactions between LLMs and users. It effectively filters both\nuser inputs and model outputs to mitigate key harm types, including offensive language, hate speech,\nmisinformation, and explicit content. The models scalability, with options ranging from 2B to 27B\nparameters, allows for tailored applications that meet specific needs, such as reducing latency in online\nsafety applications or enhancing performance in complex decision-making tasks.\nA distinguishing feature of ShieldGemma is its novel approach to data curation. It leverages synthetic\ndata generation techniques to create high-quality datasets that are robust against adversarial prompts\nand fair across diverse identity groups. This reduces the need for extensive human annotation, streamlin-\ning the data preparation process while ensuring the models effectiveness. Compared to existing content\nmoderation tools like LlamaGuard and WildGuard, which typically offer fixed-size models and limited\ncustomisation, ShieldGemmas flexible architecture and advanced data handling capabilities provide a\nmore adaptable and efficient solution.\nThese innovations position ShieldGemma as a significant ad-\nvancement in LLM-based content moderation, offering developers and researchers a versatile tool that\npromotes safer and more reliable AI interactions across various platforms.\nPython Library: The ShieldGemma series is available on HuggingFace via AutoModelForCausalLM.\nThe models can be accessed here. A tutorial for running ShieldGemma 2B on Google Colab can be found\nhere. Similar to Llama Guard series, ShieldGemma series also has guidelines for prompting and it can\nbe found here.\n7.9.3\nWILDGUARD\nWILDGUARD [82] is an innovative open-source tool developed to enhance the safety of interactions\nwith large language models (LLMs).\nThis tool addresses three critical moderation tasks: detecting\n2https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoModelForCausalLM\n63\nharmful intent in user prompts, identifying safety risks in model responses, and determining when a\nmodel appropriately refuses unsafe requests.\nCentral to its development is WILDGUARD MIX3, a\nmeticulously curated dataset comprising 92,000 labelled examples that include both benign prompts and\nadversarial attempts to bypass safety measures. The dataset is divided into WILDGUARD TRAIN, used\nfor training the model, and WILDGUARD TEST, consisting of high-quality human-annotated examples\nfor evaluation.\nThe WILDGUARD model itself is fine-tuned on the Mistral-7B language model using the WILDGUARD\nTRAIN dataset, enabling it to perform all three moderation tasks in a unified, multi-task manner. Results\nshow that WILDGUARD surpasses existing open-source moderation tools in effectiveness, particularly\nexcelling in handling adversarial prompts and accurately detecting model refusals. On many benchmarks,\nWILDGUARDs performance is on par with or exceeds that of GPT-4, a much larger, closed-source\nmodel.\nThe quick start guide and additional information on WILDGUARD are available in GitHub and it can\nbe accessed here.\n3https://huggingface.co/datasets/allenai/wildguardmix\n64\nChapter 8\nStage 6: Deployment\n8.1\nSteps Involved in Deploying the Fine-Tuned Model\n1. Model Export: Save the fine-tuned model in a suitable format (e.g., ONNX, TensorFlow Saved-\nModel, PyTorch) for deployment.\n2. Infrastructure Setup: Prepare the deployment environment, including necessary hardware, cloud\nservices, and containerisation tools.\n3. API Development: Create APIs to allow applications to interact with the model, facilitating\nprediction requests and responses.\n4. Deployment: Deploy the model to the production environment, making it accessible to end-users\nor applications.\n8.2\nCloud-Based Providers for LLM Deployment\nCloud-based large language model (LLM) inferencing frequently employs a pricing model based on the\nnumber of tokens processed. Users are charged according to the volume of text analysed or generated\nby the model. While this pricing structure can be cost-effective for sporadic or small-scale usage, it may\nnot always be economical for larger or continuous workloads.\nIn some scenarios, hosting an LLM solution in-house may offer better long-term cost savings, especially if\nthere is consistent or high-volume usage. Managing your own infrastructure provides greater control over\nresource allocation and allows for cost optimisation based on specific needs. Additionally, self-hosting\noffers advantages in terms of data privacy and security, as sensitive information remains within your own\nenvironment.\nHowever, it is crucial to carefully evaluate the total cost of ownership when comparing cloud-based\nsolutions with self-hosted alternatives. This evaluation should consider factors such as hardware expenses,\nmaintenance, and operational overheads. Ultimately, the decision should", " high-volume usage. Managing your own infrastructure provides greater control over\nresource allocation and allows for cost optimisation based on specific needs. Additionally, self-hosting\noffers advantages in terms of data privacy and security, as sensitive information remains within your own\nenvironment.\nHowever, it is crucial to carefully evaluate the total cost of ownership when comparing cloud-based\nsolutions with self-hosted alternatives. This evaluation should consider factors such as hardware expenses,\nmaintenance, and operational overheads. Ultimately, the decision should be informed by a comprehensive\ncost-benefit analysis, considering both short-term affordability and long-term sustainability.\nSeveral companies offer deployment services for large language models (LLMs), providing a range of\ntools and platforms to efficiently implement and manage these models. Heres a detailed list of some\nprominent providers and their services:\n Amazon Web Services (AWS)\n Amazon Bedrock: This service offers a suite of foundation models including Amazon Ti-\ntan, which supports various NLP tasks such as summarisation and text generation. Bedrock\nintegrates seamlessly with other AWS services for scalable and secure deployment.\n Amazon SageMaker: Provides an end-to-end machine learning service that includes tools\nfor building, training, and deploying LLMs. SageMaker JumpStart offers pre-trained models\nand step-by-step guides to simplify the deployment process.\n65\n Tutorial: This tutorial explains the deployment of LLM Agents on Amazon Bedrock. An-\nother tutorial explains end-to-end fine-tuning and deployment of LLMs with Sagemaker Can-\nvas and Amazon Bedrock. General guidelines of Amazon Bedrock for LLM users can be found\nhere.\n Microsoft Azure\n Azure OpenAI Service: This service offers access to OpenAIs powerful models like GPT-\n3.5 and Codex. It provides capabilities for embedding, image generation with DALL-E, and\nspeech-to-text with Whisper. Azures integration with OpenAI models ensures robust deploy-\nment options for various applications.\n Azure Machine Learning: Supports the deployment of custom and pre-trained models,\noffering tools for model management, deployment, and monitoring. It integrates with Azures\nbroader ecosystem for scalable and secure ML operations.\n Tutorial: Here is the tutorial for creating and deploying an Azure OpenAI Service in Mi-\ncrosoft Azure platform.\n Google Cloud Platform (GCP)\n Vertex AI: This platform allows the deployment of large language models with tools for\ntraining, tuning, and serving models. Vertex AI supports models like BERT and GPT-3,\nproviding extensive MLOps capabilities for end-to-end management.\n Cloud AI API: Offers APIs for NLP tasks such as translation, sentiment analysis, and\nentity recognition. These APIs are backed by Googles powerful infrastructure, ensuring high\nperformance and reliability.\n Tutorial: This document contains a tutorial for training and deploying an LLM in GCP.\n Hugging Face\n Inference API: This service allows users to deploy and manage LLMs hosted on Hugging\nFaces infrastructure. It supports various models from the Transformers library and provides\nan easy-to-use API for integrating these models into applications.\n Spaces: A collaborative environment where users can deploy and share models using Hugging\nFaces hosting platform. It supports deploying custom models and interactive demos.\n Tutorial: This document contains a tutorial for training and deploying an LLM using Hug-\ngingFace Inference API.\n Other Platforms\n OpenLLM: Provides deployment solutions here.\n Deepseed: Offers deployment solutions here.\n8.3\nTechniques for Optimising Model Performance During In-\nference\nOptimising model performance during inference is crucial for the efficient deployment of large language\nmodels (LLMs). The following advanced techniques offer various strategies to enhance performance,\nreduce latency, and manage computational resources effectively.\n8.3.1\nTraditional On-Premises GPU-Based Deployments\nThis conventional approach to deploying large language models (LLMs) involves using Graphics Process-\ning Units (GPUs) due to their parallel processing capabilities, which enable fast and efficient inference.\nHowever, this method requires upfront hardware investment and may not be suitable for applications\nwith fluctuating demand or limited budgets. GPU-based deployments face several challenges:\n1. Resource utilisation may suffer during periods of low demand due to idle servers.\n2. Scaling up or down often requires physical hardware modifications, which can be time-consuming.\n66\n3. Centralised servers can introduce single points of failure and scalability limitations.\nTo mitigate these issues, strategies such as load balancing between multiple GPUs, fallback routing, model\nparallelism, and data parallelism can be employed to achieve better results. Optimisation techniques like\ndistributed inference using PartialState from accelerate can further enhance efficiency.\nExample use case: Large-Scale NLP Application\nFor instance, a large e-commerce platform implemented traditional on-premises GPU-based deployment\nto handle millions of customer queries daily. By utilising load balancing and model parallelism, they\nwere able to achieve a significant reduction in latency and improved customer satisfaction.\n8.3.2\nDistributed LLM: Torrent-Style Deployment and Parallel Forward Passes\nAn innovative deployment strategy for large language models (LLMs) involves distributing them across\nmultiple GPUs in a decentralised, torrent-style manner. Libraries like Petals1 can perform this task.\nPetals functions as a decentralised pipeline designed for rapid neural network inference by partitioning\nthe model into distinct blocks or layers, which are distributed across multiple geographically dispersed\nservers. Users can connect their own GPUs to this network, acting as both contributors and clients who\ncan access and apply the model to their data.\nWhen a client request is received, the network routes it through a series of servers optimised to minimise\nthe total forward pass time. Each server dynamically selects the most optimal set of blocks, adapting to\nthe current bottlenecks in the", " inference by partitioning\nthe model into distinct blocks or layers, which are distributed across multiple geographically dispersed\nservers. Users can connect their own GPUs to this network, acting as both contributors and clients who\ncan access and apply the model to their data.\nWhen a client request is received, the network routes it through a series of servers optimised to minimise\nthe total forward pass time. Each server dynamically selects the most optimal set of blocks, adapting to\nthe current bottlenecks in the pipeline. This framework leverages decentralisation principles to distribute\ncomputational load across diverse regions, sharing computational resources and GPUs in a way that\nreduces the financial burden on individual organisations. This collaborative approach not only optimises\nresource utilisation but also fosters a global community dedicated to shared AI goals.\nFigure 8.1: Conceptual Representation of Distributed LLM Deployment Using a Torrent-Style Approach.\nThis figure illustrates the distributed deployment of a Large Language Model (LLM) using a torrent-style\napproach, where multiple GPT model layers (stacks) are distributed across different nodes (represented\nby chefs) and perform parallel forward passes. The process mimics the flow of orders from customers\n(input data) through restaurants (intermediate processing layers) to chefs (model layers), highlighting\nthe efficiency of parallel processing and distributed computing in handling large-scale language models.\nThis approach is essential for reducing inference latency and improving the scalability of LLMs across\ndiverse computational environments. (adapted from [83])\n1https://github.com/bigscience-workshop/petals\n67\nExample use case: Global Research Collaboration\nA consortium of research institutions implemented a distributed LLM using the Petals framework to\nanalyse large datasets across different continents. By leveraging the decentralised nature of Petals, they\nachieved high efficiency in processing and collaborative model development.\n8.3.3\nWebGPU-Based Deployment of LLM\nThis deployment option for large language models (LLMs) involves utilising WebGPU, a web standard\nthat provides a low-level interface for graphics and compute applications on the web platform. With\nWebGPU, organisations can harness the power of GPUs directly within web browsers, enabling effi-\ncient inference for LLMs in web-based applications. WebGPU enables high-performance computing and\ngraphics rendering directly within the clients web browser. It allows developers to utilise the clients\nGPU for tasks such as rendering graphics, accelerating computational workloads, and performing par-\nallel processing, all without the need for plugins or additional software installations. This capability\npermits complex computations to be executed efficiently on the clients device, leading to faster and\nmore responsive web applications.\n8.3.4\nLLM on WebGPU using WebLLM\nClients can access powerful large language models and chatbots directly in their browser, leveraging\nWebGPU acceleration. This approach eliminates server dependencies, providing users with exceptional\nperformance and enhanced privacy. WebLLM facilitates the use of large language models directly in the\nclients browser to perform tasks such as filtering out personally identifiable information (PII) or named\nentity recognition (NER) on data without transmitting it over the network.\nThis ensures enhanced\nprivacy and security by retaining sensitive information on the client side.\n68\nFigure 8.2: WebGPU-Based Deployment of LLM: This diagram illustrates the architecture of deploying\na large language model (LLM) using WebGPU technology. The CPU manages the distribution of prompt\ninferencing tasks to multiple GPUs, which then process these prompts in parallel, enhancing efficiency\nand scalability in LLM deployment across web-based platforms. (adapted from [83])\nAdditional Use Cases for WebLLM\n1. Language Translation: Enable real-time translation of text directly in the browser, allowing\nusers to communicate across language barriers without transmitting their messages over the net-\nwork.\n2. Code Autocompletion: Develop code editors that provide intelligent autocompletion suggestions\nbased on context, leveraging WebLLM to understand and predict code snippets.\n3. Customer Support Chatbots: Implement chatbots on websites to provide instant customer\nsupport and answer frequently asked questions without relying on external servers.\n4. Data Analysis and Visualisation: Create browser-based tools for analysing and visualising\ndata, with WebLLM assisting in data processing, interpretation, and generating insights.\n5. Personalised Recommendations:\nDevelop recommendation engines that offer personalised\nproduct recommendations, content suggestions, or movie/music recommendations based on user\npreferences and behaviour.\n6. Privacy-Preserving Analytics: Develop analytics platforms that perform data analysis directly\nin the browser, ensuring that sensitive information remains on the client side and reducing the risk\nof data breaches.\n69\nExample use case: Privacy-Focused Web Application\nA healthcare startup deployed an LLM using WebLLM to process patient information directly within the\nbrowser, ensuring data privacy and compliance with healthcare regulations. This approach significantly\nreduced the risk of data breaches and improved user trust.\n8.3.5\nQuantised LLMs\nModel quantisation is a technique utilised to reduce the size of an AI model by representing its parameters\nwith fewer bits. In traditional machine learning models, each parameter (e.g., weights and biases in neural\nnetworks) is typically stored as a 32-bit floating-point number, necessitating significant memory and\ncomputational resources, particularly for large models. Quantisation aims to alleviate this by reducing\nthe precision of these parameters. For instance, instead of storing each parameter as a 32-bit floating-\npoint number, they may be represented using fewer bits, such as 8-bit integers.\nThis compression\nreduces the memory footprint of the model, making it more efficient to deploy and execute, especially in\nresource-constrained environments like mobile devices or edge devices. QLoRA is a popular example of\nthis quantisation for LLMs"], "parameters": {"model": "nomic-embed-text:v1.5"}}, "key": "embeddings_83d1840cd9271b83e1e9474b6feb2d426bc227c3e81da3833a1d5b7276dd82cd_v2"}